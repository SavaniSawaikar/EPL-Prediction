{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Concatenate\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        Date  Day  Month  Year  DayOfWeek  HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR      Referee    HS    AS   HST  AST   HC   AC    HF    AF   HY   AY   HR   AR  H14  A14 Attendance  Strictness  Season  Round  Hpts  Apts  HTS  ATS  HGSR  AGSR  Home_DS  Away_DS  Home_Form_Points  Away_Form_Points  Home_Goal_Diff_Form  Away_Goal_Diff_Form  Home_Win_Streak  Away_Win_Streak  Home_H2H_Win_Rate  Away_H2H_Win_Rate  HTV($m)  ATV($m)  HTPos_avg  ATPos_avg  HSPE (%)  HPE (%)  ASPE (%)  APE (%)\n",
      "0           0  19/08/2000   19      8  2000          7  Charlton       Man City   4.0   0.0   H   2.0   0.0   H     R Harris  17.0   8.0  14.0  4.0  6.0  6.0  13.0  12.0  1.0  2.0  0.0  0.0    0    0     20,043   15.272727    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0      NaN      NaN        NaN        NaN       NaN      NaN       NaN      NaN\n",
      "1           1  19/08/2000   19      8  2000          7   Chelsea       West Ham   4.0   2.0   H   1.0   0.0   H     G Barber  17.0  12.0  10.0  5.0  7.0  7.0  19.0  14.0  1.0  2.0  0.0  0.0    0    0     34,914   13.641026    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0      NaN      NaN        NaN        NaN       NaN      NaN       NaN      NaN\n",
      "2           2  19/08/2000   19      8  2000          7  Coventry  Middlesbrough   1.0   3.0   A   1.0   1.0   D     B Knight   6.0  16.0   3.0  9.0  8.0  4.0  15.0  21.0  5.0  3.0  1.0  0.0    0    0     20,624   12.253968    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0      NaN      NaN        NaN        NaN       NaN      NaN       NaN      NaN\n",
      "3           3  19/08/2000   19      8  2000          7     Derby    Southampton   2.0   2.0   D   1.0   2.0   A     A D'Urso   6.0  13.0   4.0  6.0  5.0  8.0  11.0  13.0  1.0  1.0  0.0  0.0    0    0     27,223   12.565657    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0      NaN      NaN        NaN        NaN       NaN      NaN       NaN      NaN\n",
      "4           4  19/08/2000   19      8  2000          7     Leeds        Everton   2.0   0.0   H   2.0   0.0   H  D Gallagher  17.0  12.0   8.0  6.0  6.0  4.0  21.0  20.0  1.0  3.0  0.0  0.0    0    0     40,010   10.110236    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0      NaN      NaN        NaN        NaN       NaN      NaN       NaN      NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/ALLDATA_v2.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Select features for KNN\n",
    "features = ['HS', 'AS', 'HST', 'AST', 'Hpts', 'Apts', 'Home_Form_Points', 'Away_Form_Points']\n",
    "target_columns = [\"HTPos_avg\", \"ATPos_avg\"]\n",
    "\n",
    "# Create a mask to identify rows with missing values\n",
    "missing_mask = df[target_columns].isnull()\n",
    "\n",
    "# Add missingness indicators to the DataFrame\n",
    "for col in target_columns:\n",
    "    df[f\"{col}_missing\"] = missing_mask[col].astype(int)\n",
    "\n",
    "# Create a copy of the data for imputation\n",
    "imputation_data = df[features + target_columns].copy()\n",
    "\n",
    "# Apply KNN imputation\n",
    "knn_imputer = KNNImputer(n_neighbors=5)\n",
    "imputed_data = knn_imputer.fit_transform(imputation_data)\n",
    "\n",
    "# Convert imputed data back to a DataFrame\n",
    "imputed_df = pd.DataFrame(imputed_data, columns=features + target_columns)\n",
    "\n",
    "# Replace only the missing values in the original DataFrame\n",
    "for col in target_columns:\n",
    "    df.loc[missing_mask[col], col] = imputed_df.loc[missing_mask[col], col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualize imputed vs. non-imputed values\n",
    "plt.hist(df['HTPos_avg'], bins=30, alpha=0.5, label='Home Pos Avg')\n",
    "plt.hist(df.loc[missing_mask['HTPos_avg'], 'HTPos_avg'], bins=30, alpha=0.5, label='Imputed Home Pos Avg')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Day  Month  Year  DayOfWeek  HomeTeam       AwayTeam FTR      Referee  H14  A14  Strictness  Season  Round  Hpts  Apts  HTS  ATS  HGSR  AGSR  Home_DS  Away_DS  Home_Form_Points  Away_Form_Points  Home_Goal_Diff_Form  Away_Goal_Diff_Form  Home_Win_Streak  Away_Win_Streak  Home_H2H_Win_Rate  Away_H2H_Win_Rate  HTPos_avg_missing  ATPos_avg_missing\n",
      "0   19      8  2000          7  Charlton       Man City   H     R Harris    0    0   15.272727    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1\n",
      "1   19      8  2000          7   Chelsea       West Ham   H     G Barber    0    0   13.641026    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1\n",
      "2   19      8  2000          7  Coventry  Middlesbrough   A     B Knight    0    0   12.253968    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1\n",
      "3   19      8  2000          7     Derby    Southampton   D     A D'Urso    0    0   12.565657    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1\n",
      "4   19      8  2000          7     Leeds        Everton   H  D Gallagher    0    0   10.110236    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.drop(columns=['Date', 'FTHG', 'FTAG', 'HTHG', 'HTAG', 'HTR', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', 'Attendance', \"HTV($m)\",\t\"ATV($m)\", \"HTPos_avg\", \"ATPos_avg\", \"HSPE (%)\", \"HPE (%)\", \"ASPE (%)\", \"APE (%)\"],axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Day  Month  Year  DayOfWeek  H14  A14  Strictness  Season  Round  Hpts  Apts  HTS  ATS  HGSR  AGSR  Home_DS  Away_DS  Home_Form_Points  Away_Form_Points  Home_Goal_Diff_Form  Away_Goal_Diff_Form  Home_Win_Streak  Away_Win_Streak  Home_H2H_Win_Rate  Away_H2H_Win_Rate  HTPos_avg_missing  ATPos_avg_missing  HomeTeam_Arsenal  HomeTeam_Aston Villa  HomeTeam_Birmingham  HomeTeam_Blackburn  HomeTeam_Blackpool  HomeTeam_Bolton  HomeTeam_Bournemouth  HomeTeam_Bradford  HomeTeam_Brentford  HomeTeam_Brighton  HomeTeam_Burnley  HomeTeam_Cardiff  HomeTeam_Charlton  HomeTeam_Chelsea  HomeTeam_Coventry  HomeTeam_Crystal Palace  HomeTeam_Derby  HomeTeam_Everton  HomeTeam_Fulham  HomeTeam_Huddersfield  HomeTeam_Hull  HomeTeam_Ipswich  HomeTeam_Leeds  HomeTeam_Leicester  HomeTeam_Liverpool  HomeTeam_Luton  HomeTeam_Man City  HomeTeam_Man United  HomeTeam_Middlesbrough  HomeTeam_Newcastle  HomeTeam_Norwich  HomeTeam_Nott'm Forest  HomeTeam_Portsmouth  HomeTeam_QPR  HomeTeam_Reading  \\\n",
      "0   19      8  2000          7    0    0   15.272727    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1             False                 False                False               False               False            False                 False              False               False              False             False             False               True             False              False                    False           False             False            False                  False          False             False           False               False               False           False              False                False                   False               False             False                   False                False         False             False   \n",
      "1   19      8  2000          7    0    0   13.641026    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1             False                 False                False               False               False            False                 False              False               False              False             False             False              False              True              False                    False           False             False            False                  False          False             False           False               False               False           False              False                False                   False               False             False                   False                False         False             False   \n",
      "2   19      8  2000          7    0    0   12.253968    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1             False                 False                False               False               False            False                 False              False               False              False             False             False              False             False               True                    False           False             False            False                  False          False             False           False               False               False           False              False                False                   False               False             False                   False                False         False             False   \n",
      "3   19      8  2000          7    0    0   12.565657    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1             False                 False                False               False               False            False                 False              False               False              False             False             False              False             False              False                    False            True             False            False                  False          False             False           False               False               False           False              False                False                   False               False             False                   False                False         False             False   \n",
      "4   19      8  2000          7    0    0   10.110236    2000      1     0     0  0.0  0.0   0.0   0.0      0.0      0.0               0.0               0.0                  0.0                  0.0                0                0                0.0                0.0                  1                  1             False                 False                False               False               False            False                 False              False               False              False             False             False              False             False              False                    False           False             False            False                  False          False             False            True               False               False           False              False                False                   False               False             False                   False                False         False             False   \n",
      "\n",
      "   HomeTeam_Sheffield United  HomeTeam_Southampton  HomeTeam_Stoke  HomeTeam_Sunderland  HomeTeam_Swansea  HomeTeam_Tottenham  HomeTeam_Watford  HomeTeam_West Brom  HomeTeam_West Ham  HomeTeam_Wigan  HomeTeam_Wolves  AwayTeam_Arsenal  AwayTeam_Aston Villa  AwayTeam_Birmingham  AwayTeam_Blackburn  AwayTeam_Blackpool  AwayTeam_Bolton  AwayTeam_Bournemouth  AwayTeam_Bradford  AwayTeam_Brentford  AwayTeam_Brighton  AwayTeam_Burnley  AwayTeam_Cardiff  AwayTeam_Charlton  AwayTeam_Chelsea  AwayTeam_Coventry  AwayTeam_Crystal Palace  AwayTeam_Derby  AwayTeam_Everton  AwayTeam_Fulham  AwayTeam_Huddersfield  AwayTeam_Hull  AwayTeam_Ipswich  AwayTeam_Leeds  AwayTeam_Leicester  AwayTeam_Liverpool  AwayTeam_Luton  AwayTeam_Man City  AwayTeam_Man United  AwayTeam_Middlesbrough  AwayTeam_Newcastle  AwayTeam_Norwich  AwayTeam_Nott'm Forest  AwayTeam_Portsmouth  AwayTeam_QPR  AwayTeam_Reading  AwayTeam_Sheffield United  AwayTeam_Southampton  AwayTeam_Stoke  AwayTeam_Sunderland  AwayTeam_Swansea  \\\n",
      "0                      False                 False           False                False             False               False             False               False              False           False            False             False                 False                False               False               False            False                 False              False               False              False             False             False              False             False              False                    False           False             False            False                  False          False             False           False               False               False           False               True                False                   False               False             False                   False                False         False             False                      False                 False           False                False             False   \n",
      "1                      False                 False           False                False             False               False             False               False              False           False            False             False                 False                False               False               False            False                 False              False               False              False             False             False              False             False              False                    False           False             False            False                  False          False             False           False               False               False           False              False                False                   False               False             False                   False                False         False             False                      False                 False           False                False             False   \n",
      "2                      False                 False           False                False             False               False             False               False              False           False            False             False                 False                False               False               False            False                 False              False               False              False             False             False              False             False              False                    False           False             False            False                  False          False             False           False               False               False           False              False                False                    True               False             False                   False                False         False             False                      False                 False           False                False             False   \n",
      "3                      False                 False           False                False             False               False             False               False              False           False            False             False                 False                False               False               False            False                 False              False               False              False             False             False              False             False              False                    False           False             False            False                  False          False             False           False               False               False           False              False                False                   False               False             False                   False                False         False             False                      False                  True           False                False             False   \n",
      "4                      False                 False           False                False             False               False             False               False              False           False            False             False                 False                False               False               False            False                 False              False               False              False             False             False              False             False              False                    False           False              True            False                  False          False             False           False               False               False           False              False                False                   False               False             False                   False                False         False             False                      False                 False           False                False             False   \n",
      "\n",
      "   AwayTeam_Tottenham  AwayTeam_Watford  AwayTeam_West Brom  AwayTeam_West Ham  AwayTeam_Wigan  AwayTeam_Wolves  Referee_A D'Urso  Referee_A Hall  Referee_A Madley  Referee_A Marriner  Referee_A Moss  Referee_A Taylor  Referee_A Wiley  Referee_B Knight  Referee_C Foy  Referee_C Kavanagh  Referee_C Pawson  Referee_C Salisbury  Referee_C Wilkes  Referee_D Bond  Referee_D Coote  Referee_D Ellaray  Referee_D Elleray  Referee_D England  Referee_D Gallagher  Referee_D Pugh  Referee_E Wolstenholme  Referee_F Taylor  Referee_G Barber  Referee_G Poll  Referee_G Scott  Referee_Graham Barber  Referee_H Webb  Referee_I Harris  Referee_I Williamson  Referee_J Brooks  Referee_J Gillett  Referee_J Gillett   Referee_J Moss  Referee_J Smith  Referee_J Winter  Referee_K Friend  Referee_K Stroud  Referee_L Mason  Referee_L Probert  Referee_L Smith  Referee_M Atkinson  Referee_M Clattenburg  Referee_M Dean  Referee_M Donohue  Referee_M Halsey  Referee_M Jones  Referee_M Messias  Referee_M Oliver  \\\n",
      "0               False             False               False              False           False            False             False           False             False               False           False             False            False             False          False               False             False                False             False           False            False              False              False              False                False           False                   False             False             False           False            False                  False           False             False                 False             False              False               False           False            False             False             False             False            False              False            False               False                  False           False              False             False            False              False             False   \n",
      "1               False             False               False               True           False            False             False           False             False               False           False             False            False             False          False               False             False                False             False           False            False              False              False              False                False           False                   False             False              True           False            False                  False           False             False                 False             False              False               False           False            False             False             False             False            False              False            False               False                  False           False              False             False            False              False             False   \n",
      "2               False             False               False              False           False            False             False           False             False               False           False             False            False              True          False               False             False                False             False           False            False              False              False              False                False           False                   False             False             False           False            False                  False           False             False                 False             False              False               False           False            False             False             False             False            False              False            False               False                  False           False              False             False            False              False             False   \n",
      "3               False             False               False              False           False            False              True           False             False               False           False             False            False             False          False               False             False                False             False           False            False              False              False              False                False           False                   False             False             False           False            False                  False           False             False                 False             False              False               False           False            False             False             False             False            False              False            False               False                  False           False              False             False            False              False             False   \n",
      "4               False             False               False              False           False            False             False           False             False               False           False             False            False             False          False               False             False                False             False           False            False              False              False              False                 True           False                   False             False             False           False            False                  False           False             False                 False             False              False               False           False            False             False             False             False            False              False            False               False                  False           False              False             False            False              False             False   \n",
      "\n",
      "   Referee_M Riley  Referee_M Salisbury  Referee_Mn Atkinson  Referee_N Barry  Referee_N Swarbrick  Referee_N Yates  Referee_O Langford  Referee_P Bankes  Referee_P Crossley  Referee_P Dowd  Referee_P Durkin  Referee_P Jones  Referee_P Taylor  Referee_P Tierney  Referee_P Walton  Referee_R Beeby  Referee_R Burton  Referee_R East  Referee_R Harris  Referee_R Jones  Referee_R Madley  Referee_R Martin  Referee_R Styles  Referee_R Welch  Referee_S Allison  Referee_S Attwell  Referee_S Barrott  Referee_S Bennett  Referee_S Dunn  Referee_S Hooper  Referee_S Lodge  Referee_S Scott  Referee_S Singh  Referee_S Tanner  Referee_St Bennett  Referee_T Bramall  Referee_T Harrington  Referee_T Robinson  Referee_U Rennie  Referee_W G  Referee_l Mason  FTR_A  FTR_D  FTR_H  \n",
      "0            False                False                False            False                False            False               False             False               False           False             False            False             False              False             False            False             False           False              True            False             False             False             False            False              False              False              False              False           False             False            False            False            False             False               False              False                 False               False             False        False            False  False  False   True  \n",
      "1            False                False                False            False                False            False               False             False               False           False             False            False             False              False             False            False             False           False             False            False             False             False             False            False              False              False              False              False           False             False            False            False            False             False               False              False                 False               False             False        False            False  False  False   True  \n",
      "2            False                False                False            False                False            False               False             False               False           False             False            False             False              False             False            False             False           False             False            False             False             False             False            False              False              False              False              False           False             False            False            False            False             False               False              False                 False               False             False        False            False   True  False  False  \n",
      "3            False                False                False            False                False            False               False             False               False           False             False            False             False              False             False            False             False           False             False            False             False             False             False            False              False              False              False              False           False             False            False            False            False             False               False              False                 False               False             False        False            False  False   True  False  \n",
      "4            False                False                False            False                False            False               False             False               False           False             False            False             False              False             False            False             False           False             False            False             False             False             False            False              False              False              False              False           False             False            False            False            False             False               False              False                 False               False             False        False            False  False  False   True  \n"
     ]
    }
   ],
   "source": [
    "one_hot_encoded_hometeam = pd.get_dummies(df['HomeTeam'], prefix='HomeTeam')\n",
    "one_hot_encoded_awayteam = pd.get_dummies(df['AwayTeam'], prefix='AwayTeam')\n",
    "one_hot_encoded_referee = pd.get_dummies(df['Referee'], prefix='Referee')\n",
    "one_hot_encoded_ftr = pd.get_dummies(df['FTR'], prefix='FTR')\n",
    "df = pd.concat([df, one_hot_encoded_hometeam, one_hot_encoded_awayteam, one_hot_encoded_referee, one_hot_encoded_ftr], axis=1)\n",
    "df = df.drop(columns=['HomeTeam', 'AwayTeam', 'Referee', 'FTR'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import keras_tuner\n",
    "\n",
    "X = df.drop(columns=['FTR_A', 'FTR_D', 'FTR_H'])\n",
    "y = df[['FTR_A', 'FTR_D', 'FTR_H']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3881 - loss: 1.1321 - val_accuracy: 0.4534 - val_loss: 1.0483 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4606 - loss: 1.0364 - val_accuracy: 0.5007 - val_loss: 1.0135 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4787 - loss: 1.0354 - val_accuracy: 0.4801 - val_loss: 1.0269 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4799 - loss: 1.0288 - val_accuracy: 0.5068 - val_loss: 1.0133 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5083 - loss: 1.0076 - val_accuracy: 0.4870 - val_loss: 1.0247 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5057 - loss: 1.0102 - val_accuracy: 0.5048 - val_loss: 1.0090 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5347 - loss: 0.9744 - val_accuracy: 0.4705 - val_loss: 1.0246 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5309 - loss: 0.9734 - val_accuracy: 0.4548 - val_loss: 1.0335 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5397 - loss: 0.9491 - val_accuracy: 0.4747 - val_loss: 1.0196 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5545 - loss: 0.9375 - val_accuracy: 0.4507 - val_loss: 1.0367 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5805 - loss: 0.9028 - val_accuracy: 0.4130 - val_loss: 1.0560 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5751 - loss: 0.8758 - val_accuracy: 0.4719 - val_loss: 1.0347 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.5893 - loss: 0.8814 - val_accuracy: 0.4685 - val_loss: 1.0387 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6039 - loss: 0.8509 - val_accuracy: 0.4582 - val_loss: 1.0538 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6159 - loss: 0.8310 - val_accuracy: 0.4562 - val_loss: 1.0751 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m181/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6374 - loss: 0.7794\n",
      "Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6372 - loss: 0.7799 - val_accuracy: 0.4247 - val_loss: 1.1093 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6489 - loss: 0.7487 - val_accuracy: 0.4459 - val_loss: 1.1413 - learning_rate: 5.0000e-04\n",
      "Epoch 18/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6750 - loss: 0.7113 - val_accuracy: 0.4459 - val_loss: 1.1684 - learning_rate: 5.0000e-04\n",
      "Epoch 19/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6946 - loss: 0.6845 - val_accuracy: 0.4384 - val_loss: 1.1616 - learning_rate: 5.0000e-04\n",
      "Epoch 20/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7094 - loss: 0.6537 - val_accuracy: 0.4452 - val_loss: 1.1756 - learning_rate: 5.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7107 - loss: 0.6429 - val_accuracy: 0.4418 - val_loss: 1.1910 - learning_rate: 5.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7197 - loss: 0.6324 - val_accuracy: 0.4466 - val_loss: 1.2386 - learning_rate: 5.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7182 - loss: 0.6053 - val_accuracy: 0.4363 - val_loss: 1.2087 - learning_rate: 5.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7538 - loss: 0.5734 - val_accuracy: 0.4623 - val_loss: 1.2544 - learning_rate: 5.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7440 - loss: 0.5657 - val_accuracy: 0.4336 - val_loss: 1.2481 - learning_rate: 5.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m179/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5709\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m183/183\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5710 - val_accuracy: 0.4527 - val_loss: 1.2625 - learning_rate: 5.0000e-04\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 6.\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.4927 - loss: 1.0348\n",
      "Test Accuracy: 0.49\n",
      "\u001b[1m57/57\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step\n",
      "Confusion Matrix:\n",
      "[[305  80 161]\n",
      " [157  85 198]\n",
      " [203 132 503]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.56      0.50       546\n",
      "           1       0.29      0.19      0.23       440\n",
      "           2       0.58      0.60      0.59       838\n",
      "\n",
      "    accuracy                           0.49      1824\n",
      "   macro avg       0.44      0.45      0.44      1824\n",
      "weighted avg       0.47      0.49      0.48      1824\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.arange(y.shape[1]),\n",
    "    y=np.argmax(y.values, axis=1)\n",
    ")\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(256, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.4),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.4),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(y_train.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, verbose=1)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=100,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[early_stopping, reduce_lr],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_original = np.argmax(y_pred, axis=1)\n",
    "y_test_original = np.argmax(y_test.values, axis=1)\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test_original, y_pred_original))\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test_original, y_pred_original))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
