{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP0036: Beat the Bookie\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Introduction](#1-Introduction)\n",
    "\n",
    "2. [Data Import](#2-Data-Import)\n",
    "\n",
    "3. [Data Transformation & Exploration](#3-Data-Transformation-&-Exploration)\n",
    "\n",
    "4. [Methodology Overview](#4-Methodology-Overview)\n",
    "\n",
    "5. [Model Training & Validation](#5-Model-Training-&-Validation) \n",
    "\n",
    "6. [Results](#6-Results)\n",
    "\n",
    "7. [Final Predictions on Test Set](#7-Final-Predictions-on-Test-Set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Configure Pandas display settings for better readability\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('../data/epl-training.csv')\n",
    "\n",
    "# Show the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Transformation & Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1. Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "N_SEASONS = 24\n",
    "MATCHES_PER_SEASON = 380\n",
    "EXPECTED_LENGTH = N_SEASONS * MATCHES_PER_SEASON\n",
    "\n",
    "# Check the initial length against the expected length\n",
    "print(f\"Length of DataFrame before cleaning: {len(df)}\")\n",
    "print(f\"This is {len(df) - EXPECTED_LENGTH} more than the expected length of {EXPECTED_LENGTH}.\")\n",
    "\n",
    "# Remove rows that are completely empty\n",
    "df.dropna(how=\"all\", inplace=True)\n",
    "\n",
    "# Check for duplicates in the first three columns\n",
    "duplicates = df.iloc[:, :3].duplicated()\n",
    "\n",
    "if duplicates.any():\n",
    "    # Get indices of duplicate rows\n",
    "    duplicate_indices = duplicates[duplicates].index.tolist()\n",
    "    print(f\"Duplicate rows found at indices: {duplicate_indices}\")\n",
    "    print(f\"Total duplicates: {len(duplicate_indices)}\")\n",
    "\n",
    "    # Remove those duplicates\n",
    "    df.drop(index=duplicate_indices, inplace=True)\n",
    "    print(f\"Duplicate rows removed. New length: {len(df)}\")\n",
    "else:\n",
    "    print(\"No duplicates found in the first three columns.\")\n",
    "\n",
    "# Print final info\n",
    "print(f\"Final length of the cleaned DataFrame: {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Web Scraping\n",
    "```py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def get_market_val(year_start, year_end):\n",
    "    \"\"\"\n",
    "    Scrapes Transfermarkt market value data for the Premier League from season year_start \n",
    "    up to (but not including) year_end. Saves the final combined data to a CSV file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fake user agent to avoid 403 Forbidden errors\n",
    "    headers = {\n",
    "        \"User-Agent\": (\n",
    "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "            \"Chrome/91.0.4472.124 Safari/537.36\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    combined_df = pd.DataFrame()\n",
    "\n",
    "    # Loop through each season in the specified range\n",
    "    for year in range(year_start, year_end):\n",
    "        data_list = []\n",
    "        print(f\"Processing season: {year}\")\n",
    "\n",
    "        # Build the Transfermarkt URL for the given season\n",
    "        url = f\"https://www.transfermarkt.com/premier-league/startseite/wettbewerb/GB1/plus/?saison_id={year}#google_vignette\"\n",
    "        \n",
    "        # Send GET request\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(f\"Status code: {response.status_code}\")\n",
    "\n",
    "        # Parse the HTML using BeautifulSoup\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Locate the table with class 'items'\n",
    "        table = soup.find('table', class_='items')\n",
    "        rows = table.find('tbody').find_all('tr')\n",
    "\n",
    "        # Extract the desired data from each row\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "            row_data = {\n",
    "                'Year': year,\n",
    "                'Club': columns[1].text.strip(),\n",
    "                'TMV': columns[6].text.strip()[1:],  # Remove the currency symbol (e.g., 'Â£')\n",
    "            }\n",
    "            data_list.append(row_data)\n",
    "\n",
    "        # Create a DataFrame for the current season\n",
    "        df = pd.DataFrame(data_list)\n",
    "\n",
    "        # Remove rows that are entirely empty\n",
    "        df = df[~df.apply(lambda row: row.astype(str).str.strip().eq('').all(), axis=1)]\n",
    "\n",
    "        # Concatenate with the main DataFrame\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "\n",
    "        # Sleep to avoid hitting the server too frequently\n",
    "        time.sleep(5)\n",
    "\n",
    "    # Save the final DataFrame to a CSV file\n",
    "    combined_df.to_csv('Engineered Data/Final Data/marketval.csv', index=False)\n",
    "    print(\"Data saved to 'Engineered Data/Final Data/marketval.csv'.\")\n",
    "\n",
    "# Example usage\n",
    "get_market_val(2000, 2025)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Exploring Scraped Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.1. 14-Day Match Density and Match Attendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import timedelta\n",
    "\n",
    "# Load data scraping CSV files\n",
    "EPL_S = pd.read_csv('../scraped-data/combined-epl.csv')\n",
    "FA_S = pd.read_csv('../scraped-data/combined-fa-e.csv')\n",
    "EFL_S = pd.read_csv('../scraped-data/combined-efl-e.csv')\n",
    "UCL_S = pd.read_csv('../scraped-data/combined-ucl-e.csv')\n",
    "UEL_S = pd.read_csv('../scraped-data/combined-uel-e.csv')\n",
    "\n",
    "# Tag each DataFrame to identify its source\n",
    "EPL_S.insert(0, 'df name', 'EPL')\n",
    "FA_S.insert(0, 'df name', 'FA')\n",
    "EFL_S.insert(0, 'df name', 'EFL')\n",
    "UCL_S.insert(0, 'df name', 'UCL')\n",
    "UEL_S.insert(0, 'df name', 'UEL')\n",
    "\n",
    "# Combine all DataFrames into one\n",
    "combined = pd.concat([EPL_S, FA_S, EFL_S, UCL_S, UEL_S], ignore_index=True)\n",
    "\n",
    "# Convert the 'Date' columns to datetime using DD/MM/YYYY format\n",
    "# (Fixes warning about parsing with dayfirst=False)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "combined['Date'] = pd.to_datetime(combined['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Sort the combined DataFrame by date and home team\n",
    "combined.sort_values(['Date', 'HomeTeam'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# Define a function to count matches for a given team in the prior 14 days\n",
    "def calculate_matches(team, match_date):\n",
    "    start_date = match_date - timedelta(days=14)\n",
    "    matches = combined.loc[\n",
    "        (\n",
    "            (combined['HomeTeam'] == team) |\n",
    "            (combined['AwayTeam'] == team)\n",
    "        ) &\n",
    "        (combined['Date'] >= start_date) &\n",
    "        (combined['Date'] < match_date)\n",
    "    ]\n",
    "    return len(matches)\n",
    "\n",
    "# Filter EPL rows and make a copy to avoid SettingWithCopyWarning\n",
    "combined_epl = combined.loc[combined['df name'] == 'EPL'].copy()\n",
    "\n",
    "# Calculate 14-day match density for home and away teams\n",
    "combined_epl['H14'] = combined_epl.apply(\n",
    "    lambda row: calculate_matches(row['HomeTeam'], row['Date']), axis=1\n",
    ")\n",
    "combined_epl['A14'] = combined_epl.apply(\n",
    "    lambda row: calculate_matches(row['AwayTeam'], row['Date']), axis=1\n",
    ")\n",
    "\n",
    "# Merge H14, A14, and Attendance columns into the main epl DataFrame\n",
    "df = df.merge(\n",
    "    combined_epl[['Date', 'HomeTeam', 'AwayTeam', 'H14', 'A14', 'Attendance']],\n",
    "    on=['Date', 'HomeTeam', 'AwayTeam'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Convert the Date column back to DD/MM/YYYY format for consistency\n",
    "df['Date'] = df['Date'].dt.strftime('%d/%m/%Y')\n",
    "\n",
    "# Preview the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.2. Referee Strictness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to standardize referee names based on index ranges\n",
    "def StandardNames(index, name):\n",
    "    \"\"\"\n",
    "    Standardizes referee names differently depending on the row index.\n",
    "    \"\"\"\n",
    "    # First 380 rows: split and keep first initial + last name\n",
    "    if index <= 379:\n",
    "        parts = name.split()\n",
    "        if len(parts) > 1:\n",
    "            return f\"{parts[0][0]} {parts[1]}\"\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "    # Rows 380 to 549: remove periods, then keep first initial + last name\n",
    "    elif index <= 549:\n",
    "        parts = name.replace('.', '').split()\n",
    "        if len(parts) > 1:\n",
    "            return f\"{parts[0][0]} {parts[-1]}\"\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "    # Rows 550 to 759: remove commas/periods, swap order, keep first initial + last name\n",
    "    elif index <= 759:\n",
    "        parts = name.replace(',', '').replace('.', '').split()\n",
    "        if len(parts) > 1:\n",
    "            return f\"{parts[1][0]} {parts[0]}\"\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "    # Rows 1855 to 1863: keep last letter of first name + last name\n",
    "    elif index >= 1855 and index <= 1863:\n",
    "        parts = name.split()\n",
    "        if len(parts) > 1:\n",
    "            return f\"{parts[0][-1]} {parts[1]}\"\n",
    "        else:\n",
    "            return name\n",
    "\n",
    "    # Default: do not modify name\n",
    "    else:\n",
    "        return name\n",
    "\n",
    "# Apply the StandardNames function to each row\n",
    "df['Referee'] = df.apply(lambda row: StandardNames(row.name, row['Referee']), axis=1)\n",
    "\n",
    "# Define a lookup dictionary for inconsistent names\n",
    "name_corrections = {\n",
    "    \"D Gallaghe\": \"D Gallagher\",\n",
    "    \"D Gallagh\": \"D Gallagher\"\n",
    "}\n",
    "\n",
    "# Apply corrections to the 'Referee' column\n",
    "df['Referee'] = df['Referee'].apply(\n",
    "    lambda name: name_corrections[name] if name in name_corrections else name\n",
    ")\n",
    "\n",
    "# Get unique refs and initialize dictionaries\n",
    "refs = df['Referee'].unique()\n",
    "Y = {ref: 0 for ref in refs}\n",
    "R = {ref: 0 for ref in refs}\n",
    "MatchCount = {ref: 0 for ref in refs}\n",
    "strictness = {}\n",
    "\n",
    "# Loop over DataFrame rows to count yellow/red cards and appearances\n",
    "for index, row in df.iterrows():\n",
    "    ref = row['Referee']\n",
    "    if pd.notna(ref):\n",
    "        Y[ref] += row['AY'] + row['HY']  # Summation of all yellow cards\n",
    "        R[ref] += row['AY'] + row['HY']  # In the original code: same as above (possibly an intentional choice)\n",
    "        MatchCount[ref] += 1\n",
    "\n",
    "# Compute \"strictness\" based on total cards and matches\n",
    "for ref in refs:\n",
    "    if MatchCount[ref] > 0:\n",
    "        strictness[ref] = (Y[ref] + 3 * R[ref]) / MatchCount[ref]\n",
    "    else:\n",
    "        strictness[ref] = 0\n",
    "\n",
    "# Add a 'Strictness' column to the epl DataFrame\n",
    "df['Strictness'] = df['Referee'].map(strictness)\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.3. Standings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Enable tqdm for Pandas apply operations\n",
    "tqdm.pandas()\n",
    "\n",
    "# Convert FTR to winner name or 'Draw'\n",
    "df['FTR'] = df.apply(\n",
    "    lambda row: row['HomeTeam'] if row['FTR'] == 'H' \n",
    "                else ('Draw' if row['FTR'] == 'D' else row['AwayTeam']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Assign 'Season' based on row index (380 matches per season)\n",
    "df['Season'] = df.index // 380\n",
    "df['Season'] = df['Season'].apply(lambda i: 2000 + i)  # e.g., 0 -> 2000, 1 -> 2001, etc.\n",
    "\n",
    "# Assign 'Round' values (there are 38 rounds in a 380-match season)\n",
    "roundindex = (df.index - 10) // 10 + 1\n",
    "df['Round'] = (roundindex % 38) + 1\n",
    "\n",
    "# Recursive function to calculate cumulative points\n",
    "def get_pts(team, season, current_round):\n",
    "    \"\"\"\n",
    "    Returns the points accumulated by 'team' up to (and including) 'current_round'\n",
    "    in 'season' (where season=2018 means 2018-2019, etc.).\n",
    "    \"\"\"\n",
    "    if current_round == 1:\n",
    "        return 0\n",
    "    \n",
    "    # Filter for the previous round in the same season\n",
    "    prev_round_data = df[\n",
    "        (df['Season'] == season) & \n",
    "        (df['Round'] == current_round - 1)\n",
    "    ]\n",
    "    \n",
    "    # Conditions to check if the team won or drew in the previous round\n",
    "    homewin = (prev_round_data['HomeTeam'] == team) & (prev_round_data['FTR'] == team)\n",
    "    awaywin = (prev_round_data['AwayTeam'] == team) & (prev_round_data['FTR'] == team)\n",
    "    draw = (\n",
    "        ((prev_round_data['HomeTeam'] == team) | (prev_round_data['AwayTeam'] == team)) \n",
    "        & (prev_round_data['FTR'] == 'Draw')\n",
    "    )\n",
    "\n",
    "    # Points in the previous round\n",
    "    if homewin.any() or awaywin.any():\n",
    "        roundpts = 3\n",
    "    elif draw.any():\n",
    "        roundpts = 1\n",
    "    else:\n",
    "        roundpts = 0\n",
    "    \n",
    "    # Recursively add the points from earlier rounds\n",
    "    return roundpts + get_pts(team, season, current_round - 1)\n",
    "\n",
    "# Calculate home and away teams' cumulative points\n",
    "df['Hpts'] = df.progress_apply(\n",
    "    lambda row: get_pts(row['HomeTeam'], row['Season'], row['Round']), \n",
    "    axis=1\n",
    ")\n",
    "df['Apts'] = df.progress_apply(\n",
    "    lambda row: get_pts(row['AwayTeam'], row['Season'], row['Round']), \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Revert FTR back to 'H', 'D', or 'A'\n",
    "df['FTR'] = df.progress_apply(\n",
    "    lambda row: 'H' if row['FTR'] == row['HomeTeam']\n",
    "                else ('D' if row['FTR'] == 'Draw' else 'A'),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Show the first few rows\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.4. Other Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, deque\n",
    "\n",
    "# Temporarily add the HomePoints/AwayPoints features for easier tracking of match outcomes\n",
    "df['HomePoints'] = df['FTR'].apply(lambda x: 3 if x == 'H' else (1 if x == 'D' else 0))\n",
    "df['AwayPoints'] = df['FTR'].apply(lambda x: 3 if x == 'A' else (1 if x == 'D' else 0))\n",
    "\n",
    "# Define rolling window size for form metrics (e.g., last 10 matches)\n",
    "form_window = 10\n",
    "\n",
    "# Dictionaries to track stats for each team\n",
    "team_strength_stats = {}      # Contains overall points & games played\n",
    "team_goals_scored = {}        # Cumulative goals scored by each team\n",
    "team_goals_conceded = {}      # Cumulative goals conceded by each team\n",
    "team_form_points = {}         # Rolling points over last `form_window` matches\n",
    "team_form_goal_diff = {}      # Rolling goal difference over last `form_window` matches\n",
    "team_win_streak = {}          # Current win streak\n",
    "h2h_record = defaultdict(lambda: {\"matches\": 0, \"home_wins\": 0, \"away_wins\": 0})  # H2H stats\n",
    "\n",
    "# --- Helper Functions ---\n",
    "\n",
    "# Overall team strength\n",
    "def get_team_strength(team):\n",
    "    if team in team_strength_stats and team_strength_stats[team]['games'] > 0:\n",
    "        return team_strength_stats[team]['points'] / team_strength_stats[team]['games']\n",
    "    return 0\n",
    "\n",
    "def update_team_strength(team, points):\n",
    "    if team not in team_strength_stats:\n",
    "        team_strength_stats[team] = {'points': 0, 'games': 0}\n",
    "    team_strength_stats[team]['points'] += points\n",
    "    team_strength_stats[team]['games'] += 1\n",
    "\n",
    "# Goal scoring rate\n",
    "def get_goal_scoring_rate(team):\n",
    "    if team in team_goals_scored and team_strength_stats[team]['games'] > 0:\n",
    "        return team_goals_scored[team] / team_strength_stats[team]['games']\n",
    "    return 0\n",
    "\n",
    "def update_goal_scoring_rate(team, goals):\n",
    "    if team not in team_goals_scored:\n",
    "        team_goals_scored[team] = 0\n",
    "    team_goals_scored[team] += goals\n",
    "\n",
    "# Defensive strength\n",
    "def get_defensive_strength(team):\n",
    "    if team in team_goals_conceded and team_strength_stats[team]['games'] > 0:\n",
    "        return team_goals_conceded[team] / team_strength_stats[team]['games']\n",
    "    return 0\n",
    "\n",
    "def update_defensive_strength(team, goals_conceded):\n",
    "    if team not in team_goals_conceded:\n",
    "        team_goals_conceded[team] = 0\n",
    "    team_goals_conceded[team] += goals_conceded\n",
    "\n",
    "# Team form (last `form_window` matches)\n",
    "def get_form_points(team):\n",
    "    if team in team_form_points and len(team_form_points[team]) > 0:\n",
    "        return sum(team_form_points[team]) / len(team_form_points[team])\n",
    "    return 0\n",
    "\n",
    "def update_form_points(team, points):\n",
    "    if team not in team_form_points:\n",
    "        team_form_points[team] = deque(maxlen=form_window)\n",
    "    team_form_points[team].append(points)\n",
    "\n",
    "def get_goal_diff_form(team):\n",
    "    if team in team_form_goal_diff and len(team_form_goal_diff[team]) > 0:\n",
    "        return sum(team_form_goal_diff[team])\n",
    "    return 0\n",
    "\n",
    "def update_goal_diff_form(team, goal_diff):\n",
    "    if team not in team_form_goal_diff:\n",
    "        team_form_goal_diff[team] = deque(maxlen=form_window)\n",
    "    team_form_goal_diff[team].append(goal_diff)\n",
    "\n",
    "def get_win_streak(team):\n",
    "    return team_win_streak.get(team, 0)\n",
    "\n",
    "def update_win_streak(team, result):\n",
    "    if team not in team_win_streak:\n",
    "        team_win_streak[team] = 0\n",
    "    if result == 3:  # Win\n",
    "        team_win_streak[team] += 1\n",
    "    else:            # Loss or Draw\n",
    "        team_win_streak[team] = 0\n",
    "\n",
    "# H2H functions\n",
    "def calculate_h2h_win_rate(team, opponent, is_home):\n",
    "    record = h2h_record[(team, opponent)]\n",
    "    wins = record['home_wins'] if is_home else record['away_wins']\n",
    "    total_matches = record['matches']\n",
    "    return wins / total_matches if total_matches > 0 else 0\n",
    "\n",
    "def update_h2h_record(home_team, away_team, result):\n",
    "    h2h_record[(home_team, away_team)]['matches'] += 1\n",
    "    h2h_record[(away_team, home_team)]['matches'] += 1\n",
    "    if result == 'H':\n",
    "        h2h_record[(home_team, away_team)]['home_wins'] += 1\n",
    "    elif result == 'A':\n",
    "        h2h_record[(away_team, home_team)]['away_wins'] += 1\n",
    "\n",
    "# --- Lists to store computed metrics for each row ---\n",
    "hts_list = []\n",
    "ats_list = []\n",
    "home_gsr_list = []\n",
    "away_gsr_list = []\n",
    "home_ds_list = []\n",
    "away_ds_list = []\n",
    "home_form_points_list = []\n",
    "away_form_points_list = []\n",
    "home_goal_diff_form_list = []\n",
    "away_goal_diff_form_list = []\n",
    "home_win_streak_list = []\n",
    "away_win_streak_list = []\n",
    "home_h2h_win_rate_list = []\n",
    "away_h2h_win_rate_list = []\n",
    "\n",
    "# --- Main loop to process each match ---\n",
    "for _, row in df.iterrows():\n",
    "    home_team = row['HomeTeam']\n",
    "    away_team = row['AwayTeam']\n",
    "    result = row['FTR']\n",
    "    \n",
    "    # Calculate current metrics before updating\n",
    "    hts = get_team_strength(home_team)\n",
    "    ats = get_team_strength(away_team)\n",
    "    home_gsr = get_goal_scoring_rate(home_team)\n",
    "    away_gsr = get_goal_scoring_rate(away_team)\n",
    "    home_ds = get_defensive_strength(home_team)\n",
    "    away_ds = get_defensive_strength(away_team)\n",
    "    home_form_points = get_form_points(home_team)\n",
    "    away_form_points = get_form_points(away_team)\n",
    "    home_goal_diff_form = get_goal_diff_form(home_team)\n",
    "    away_goal_diff_form = get_goal_diff_form(away_team)\n",
    "    home_win_streak = get_win_streak(home_team)\n",
    "    away_win_streak = get_win_streak(away_team)\n",
    "    home_h2h_win_rate = calculate_h2h_win_rate(home_team, away_team, is_home=True)\n",
    "    away_h2h_win_rate = calculate_h2h_win_rate(away_team, home_team, is_home=False)\n",
    "    \n",
    "    # Append values to lists\n",
    "    hts_list.append(hts)\n",
    "    ats_list.append(ats)\n",
    "    home_gsr_list.append(home_gsr)\n",
    "    away_gsr_list.append(away_gsr)\n",
    "    home_ds_list.append(home_ds)\n",
    "    away_ds_list.append(away_ds)\n",
    "    home_form_points_list.append(home_form_points)\n",
    "    away_form_points_list.append(away_form_points)\n",
    "    home_goal_diff_form_list.append(home_goal_diff_form)\n",
    "    away_goal_diff_form_list.append(away_goal_diff_form)\n",
    "    home_win_streak_list.append(home_win_streak)\n",
    "    away_win_streak_list.append(away_win_streak)\n",
    "    home_h2h_win_rate_list.append(home_h2h_win_rate)\n",
    "    away_h2h_win_rate_list.append(away_h2h_win_rate)\n",
    "    \n",
    "    # Update stats after reading the row\n",
    "    update_team_strength(home_team, row['HomePoints'])\n",
    "    update_team_strength(away_team, row['AwayPoints'])\n",
    "    update_goal_scoring_rate(home_team, row['FTHG'])\n",
    "    update_goal_scoring_rate(away_team, row['FTAG'])\n",
    "    update_defensive_strength(home_team, row['FTAG'])\n",
    "    update_defensive_strength(away_team, row['FTHG'])\n",
    "    \n",
    "    home_goal_diff = row['FTHG'] - row['FTAG']\n",
    "    away_goal_diff = row['FTAG'] - row['FTHG']\n",
    "    update_form_points(home_team, row['HomePoints'])\n",
    "    update_form_points(away_team, row['AwayPoints'])\n",
    "    update_goal_diff_form(home_team, home_goal_diff)\n",
    "    update_goal_diff_form(away_team, away_goal_diff)\n",
    "    update_win_streak(home_team, row['HomePoints'])\n",
    "    update_win_streak(away_team, row['AwayPoints'])\n",
    "    \n",
    "    # Update head-to-head stats\n",
    "    update_h2h_record(home_team, away_team, result)\n",
    "\n",
    "# Assign computed metrics back to the DataFrame\n",
    "df['HTS'] = hts_list\n",
    "df['ATS'] = ats_list\n",
    "df['HGSR'] = home_gsr_list\n",
    "df['AGSR'] = away_gsr_list\n",
    "df['Home_DS'] = home_ds_list\n",
    "df['Away_DS'] = away_ds_list\n",
    "df['Home_Form_Points'] = home_form_points_list\n",
    "df['Away_Form_Points'] = away_form_points_list\n",
    "df['Home_Goal_Diff_Form'] = home_goal_diff_form_list\n",
    "df['Away_Goal_Diff_Form'] = away_goal_diff_form_list\n",
    "df['Home_Win_Streak'] = home_win_streak_list\n",
    "df['Away_Win_Streak'] = away_win_streak_list\n",
    "df['Home_H2H_Win_Rate'] = home_h2h_win_rate_list\n",
    "df['Away_H2H_Win_Rate'] = away_h2h_win_rate_list\n",
    "\n",
    "# Remove the temporary columns\n",
    "df.drop(columns=['HomePoints', 'AwayPoints'], inplace=True)\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.3.5. Team Market Value, Match Possession, Set Piece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load additional scraped data\n",
    "MarketVal = pd.read_csv('../scraped-data/market-values.csv')\n",
    "Posession = pd.read_csv('../scraped-data/possession-data.csv')\n",
    "SetPiece = pd.read_csv('../scraped-data/set-piece.csv')\n",
    "\n",
    "# Dictionary for team name corrections\n",
    "Alterations = {\n",
    "    'Manchester City': 'Man City',\n",
    "    'Arsenal FC': 'Arsenal',\n",
    "    'Chelsea FC': 'Chelsea',\n",
    "    'Liverpool FC': 'Liverpool',\n",
    "    'Manchester United': 'Man United',\n",
    "    'Tottenham Hotspur': 'Tottenham',\n",
    "    'Newcastle United': 'Newcastle',\n",
    "    'Brighton & Hove Albion': 'Brighton',\n",
    "    'West Ham United': 'West Ham',\n",
    "    'Nottingham Forest': \"Nott'm Forest\",\n",
    "    'Brentford FC': 'Brentford',\n",
    "    'Wolverhampton Wanderers': 'Wolves',\n",
    "    'AFC Bournemouth': 'Bournemouth',\n",
    "    'Everton FC': 'Everton',\n",
    "    'Fulham FC': 'Fulham',\n",
    "    'Southampton FC': 'Southampton',\n",
    "    'Leicester City': 'Leicester',\n",
    "    'Ipswich Town': 'Ipswich',\n",
    "    'West Bromwich Albion': 'West Brom',\n",
    "    'Queens Park Rangers': 'QPR',\n",
    "    'Hull City': 'Hull',\n",
    "    'Stoke City': 'Stoke',\n",
    "    'Swansea City': 'Swansea',\n",
    "    'Manchester Utd': 'Man United',\n",
    "    'Newcastle Utd': 'Newcastle',\n",
    "    \"Nott'ham Forest\": \"Nott'm Forest\",\n",
    "    \"Luton Town\": \"Luton\",\n",
    "    'Sheffield Utd': 'Sheffield United',\n",
    "    'Leeds United': 'Leeds',\n",
    "    'Norwich City': 'Norwich',\n",
    "    'Cardiff City': 'Cardiff',\n",
    "    'Birmingham City': 'Birmingham',\n",
    "    'Blackburn Rovers': 'Blackburn',\n",
    "    'Blackpool FC': 'Blackpool',\n",
    "    'Bolton Wanderers': 'Bolton',\n",
    "    'Bradford City': 'Bradford',\n",
    "    'Burnley FC': 'Burnley',\n",
    "    'Charlton Athletic': 'Charlton',\n",
    "    'Coventry City': 'Coventry',\n",
    "    'Derby County': 'Derby',\n",
    "    'Huddersfield Town': 'Huddersfield',\n",
    "    'Middlesbrough FC': 'Middlesbrough',\n",
    "    'Portsmouth FC': 'Portsmouth',\n",
    "    'Reading FC': 'Reading',\n",
    "    'Sunderland AFC': 'Sunderland',\n",
    "    'Watford FC': 'Watford',\n",
    "    'Wigan Athletic': 'Wigan',\n",
    "}\n",
    "\n",
    "# Apply team name corrections in each DataFrame\n",
    "MarketVal['Club'] = MarketVal['Club'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "Posession['Team'] = Posession['Team'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "SetPiece['Team'] = SetPiece['Team'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "\n",
    "# Check how many teams exist in each dataset\n",
    "cleaneplteams = list(df['HomeTeam'].unique())\n",
    "MarketValteams = list(MarketVal['Club'].unique())\n",
    "Posessionteams = list(Posession['Team'].unique())\n",
    "setPieceteams = list(SetPiece['Team'].unique())\n",
    "\n",
    "print(f\"Number of teams in the clean EPL data: {len(cleaneplteams)}\")\n",
    "print(f\"Number of teams in the MarketVal data:   {len(MarketValteams)}\")\n",
    "print(f\"Number of teams in the Possession data:  {len(Posessionteams)}\")\n",
    "print(f\"Number of teams in the SetPiece data:    {len(setPieceteams)}\")\n",
    "\n",
    "# Identify names not found in the dictionary\n",
    "uniqueepl = sorted([team for team in cleaneplteams if team not in MarketValteams])\n",
    "UniqueMarketVal = sorted([team for team in MarketValteams if team not in cleaneplteams])\n",
    "UniquePosession = [team for team in Posessionteams if team not in cleaneplteams]\n",
    "UniqueSetPiece = [team for team in setPieceteams if team not in cleaneplteams]\n",
    "\n",
    "# Apply final corrections (just in case) after the check\n",
    "MarketVal['Club'] = MarketVal['Club'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "Posession['Team'] = Posession['Team'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "SetPiece['Team'] = SetPiece['Team'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "\n",
    "# Clean MarketVal's TMV column by converting from string to numeric\n",
    "MarketVal['TMV'] = MarketVal['TMV'].apply(\n",
    "    lambda val: float(str(val)[:-2]) * 1000 if isinstance(val, str) and val.endswith('bn')\n",
    "    else (float(str(val)[:-1]) if isinstance(val, str) and val.endswith('m') else val)\n",
    ")\n",
    "\n",
    "# Merge MarketVal into `epl` for HomeTeam\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    MarketVal.rename(columns={'Club': 'HomeTeam', 'TMV': 'HTV($m)', 'Year': 'Season'}),\n",
    "    how='left',\n",
    "    on=['HomeTeam', 'Season']\n",
    ")\n",
    "\n",
    "# Merge MarketVal into `epl` for AwayTeam\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    MarketVal.rename(columns={'Club': 'AwayTeam', 'TMV': 'ATV($m)', 'Year': 'Season'}),\n",
    "    how='left',\n",
    "    on=['AwayTeam', 'Season']\n",
    ")\n",
    "\n",
    "# Process Posession data: adjust year, convert Poss to decimal\n",
    "Posession['year'] = Posession['year'].apply(lambda yr: yr[:4]).astype(int)\n",
    "Posession['Poss'] = Posession['Poss'].apply(lambda pos: pos / 100)\n",
    "Posession = Posession[['Team', 'Poss', 'year']]\n",
    "\n",
    "# Merge possession data for HomeTeam\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    Posession.rename(columns={'Team': 'HomeTeam', 'Poss': 'HTPos_avg', 'year': 'Season'}),\n",
    "    how='left',\n",
    "    on=['HomeTeam', 'Season']\n",
    ")\n",
    "\n",
    "# Merge possession data for AwayTeam\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    Posession.rename(columns={'Team': 'AwayTeam', 'Poss': 'ATPos_avg', 'year': 'Season'}),\n",
    "    how='left',\n",
    "    on=['AwayTeam', 'Season']\n",
    ")\n",
    "\n",
    "# Prepare SetPiece data: drop NaNs, adjust Season\n",
    "SetPiece = SetPiece.dropna()\n",
    "SetPiece['Season'] = SetPiece['Season'].apply(lambda yr: yr[:4]).astype(int)\n",
    "SetPiece = SetPiece[['Season', 'Team', 'Set Piece Efficiency (%)', 'Penalty Efficiency (%)']]\n",
    "\n",
    "# Merge set piece data for HomeTeam\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    SetPiece.rename(columns={\n",
    "        'Team': 'HomeTeam',\n",
    "        'Set Piece Efficiency (%)': 'HSPE (%)',\n",
    "        'Penalty Efficiency (%)': 'HPE (%)'\n",
    "    }),\n",
    "    how='left',\n",
    "    on=['HomeTeam', 'Season']\n",
    ")\n",
    "\n",
    "# Merge set piece data for AwayTeam\n",
    "df = pd.merge(\n",
    "    df,\n",
    "    SetPiece.rename(columns={\n",
    "        'Team': 'AwayTeam',\n",
    "        'Set Piece Efficiency (%)': 'ASPE (%)',\n",
    "        'Penalty Efficiency (%)': 'APE (%)'\n",
    "    }),\n",
    "    how='left',\n",
    "    on=['AwayTeam', 'Season']\n",
    ")\n",
    "\n",
    "# Preview the final DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Data Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.1. Splitting Date into Day, Month, Year, and Day of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' to datetime (DD/MM/YYYY)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Extract day, month, year, and day of the week\n",
    "day = df['Date'].dt.day\n",
    "month = df['Date'].dt.month\n",
    "year = df['Date'].dt.year\n",
    "dow_num = df['Date'].dt.dayofweek + 1\n",
    "\n",
    "# Drop the 'Date' column\n",
    "df.drop(columns='Date', inplace=True)\n",
    "\n",
    "# Insert the new columns back in starting at index 0\n",
    "df.insert(0, 'Day', day)\n",
    "df.insert(1, 'Month', month)\n",
    "df.insert(2, 'Year', year)\n",
    "df.insert(3, 'DayOfWeek', dow_num)\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.2. Imputing possession averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import numpy as np\n",
    "\n",
    "def xgb_impute_pos_avg(df):\n",
    "    \"\"\"\n",
    "    Imputes missing values in 'HTPos_avg' and 'ATPos_avg' using XGBRegressor.\n",
    "    Adds indicator columns to track which values were missing before imputation.\n",
    "    \"\"\"\n",
    "    # 1. Define the features you want to use for predicting possession\n",
    "    #    (the same ones you used for KNN, or a superset)\n",
    "    features = [\n",
    "        'HS', 'AS', 'HST', 'AST', \n",
    "        'Hpts', 'Apts', \n",
    "        'Home_Form_Points', 'Away_Form_Points'\n",
    "    ]\n",
    "    target_columns = [\"HTPos_avg\", \"ATPos_avg\"]\n",
    "\n",
    "    # 2. Create indicator columns showing which rows were missing\n",
    "    for col in target_columns:\n",
    "        df[f\"{col}_missing\"] = df[col].isnull().astype(int)\n",
    "\n",
    "    # We'll impute each column (HTPos_avg, ATPos_avg) separately via XGBoost\n",
    "    for target_col in target_columns:\n",
    "        # a) Separate known vs missing\n",
    "        not_missing_mask = df[target_col].notnull()\n",
    "        missing_mask = df[target_col].isnull()\n",
    "\n",
    "        # If no missing values, skip\n",
    "        if not df[missing_mask].empty:\n",
    "            # b) Training data (where target_col is known)\n",
    "            X_train = df.loc[not_missing_mask, features]\n",
    "            y_train = df.loc[not_missing_mask, target_col]\n",
    "\n",
    "            # c) Rows to predict (where target_col is missing)\n",
    "            X_missing = df.loc[missing_mask, features]\n",
    "\n",
    "            # d) Define & train your XGBRegressor\n",
    "            #    You can tweak these hyperparameters as needed\n",
    "            xgb_model = XGBRegressor(\n",
    "                n_estimators=300,\n",
    "                max_depth=6,\n",
    "                learning_rate=0.1,\n",
    "                subsample=0.8,\n",
    "                colsample_bytree=0.8,\n",
    "                random_state=42,\n",
    "                n_jobs=-1\n",
    "            )\n",
    "\n",
    "            xgb_model.fit(X_train, y_train)\n",
    "\n",
    "            # e) Predict and fill in the missing values\n",
    "            df.loc[missing_mask, target_col] = xgb_model.predict(X_missing)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = xgb_impute_pos_avg(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.3. Imputing HSPE and ASPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Define a function to impute missing values using a RandomForestRegressor\n",
    "def random_forest_impute(df, target_col, feature_cols):\n",
    "    \"\"\"\n",
    "    Trains a RandomForestRegressor to predict 'target_col' using 'feature_cols' \n",
    "    and fills in missing values in 'target_col' within 'df'.\n",
    "    \"\"\"\n",
    "    # Identify rows with and without missing values in the target column\n",
    "    not_missing_mask = df[target_col].notnull()\n",
    "    missing_mask = df[target_col].isnull()\n",
    "\n",
    "    df_not_missing = df[not_missing_mask]\n",
    "    df_missing = df[missing_mask]\n",
    "\n",
    "    if df_missing.empty:\n",
    "        print(f\"No missing values for {target_col}; skipping RF imputation.\")\n",
    "        return df\n",
    "\n",
    "    # Configure RandomForestRegressor\n",
    "    rf = RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=20,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Train on rows where target_col is not missing\n",
    "    rf.fit(df_not_missing[feature_cols], df_not_missing[target_col])\n",
    "\n",
    "    # Predict and fill missing values\n",
    "    imputed_values = rf.predict(df_missing[feature_cols])\n",
    "    df.loc[missing_mask, target_col] = imputed_values\n",
    "\n",
    "    return df\n",
    "\n",
    "# Example features for imputation\n",
    "rf_features = [\n",
    "    'Hpts', 'Apts',\n",
    "    'Home_Form_Points', 'Away_Form_Points',\n",
    "    'Home_H2H_Win_Rate', 'Away_H2H_Win_Rate',\n",
    "    'HTS', 'ATS'\n",
    "]\n",
    "\n",
    "# Flag rows where HSPE or ASPE is missing\n",
    "df[\"HSPE_missing\"] = df[\"HSPE (%)\"].isnull().astype(int)\n",
    "df[\"ASPE_missing\"] = df[\"ASPE (%)\"].isnull().astype(int)\n",
    "\n",
    "# Impute missing 'HSPE (%)'\n",
    "df = random_forest_impute(\n",
    "    df=df,\n",
    "    target_col='HSPE (%)',\n",
    "    feature_cols=rf_features\n",
    ")\n",
    "\n",
    "# Impute missing 'ASPE (%)'\n",
    "df = random_forest_impute(\n",
    "    df=df,\n",
    "    target_col='ASPE (%)',\n",
    "    feature_cols=rf_features\n",
    ")\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.4. Imputing HPE and APE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.experimental import enable_iterative_imputer  # noqa\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Flag rows with missing 'HPE (%)' or 'APE (%)'\n",
    "df[\"HPE_missing\"] = df[\"HPE (%)\"].isnull().astype(int)\n",
    "df[\"APE_missing\"] = df[\"APE (%)\"].isnull().astype(int)\n",
    "\n",
    "# Define features for RandomForest imputation\n",
    "rf_features_for_hpe_ape = [\n",
    "    'Hpts', 'Apts',\n",
    "    'Home_Form_Points', 'Away_Form_Points',\n",
    "    'Home_H2H_Win_Rate', 'Away_H2H_Win_Rate',\n",
    "    'HTS', 'ATS'\n",
    "]\n",
    "\n",
    "# Impute HPE (%) using a random forest\n",
    "df = random_forest_impute(\n",
    "    df=df,\n",
    "    target_col='HPE (%)',\n",
    "    feature_cols=rf_features_for_hpe_ape\n",
    ")\n",
    "\n",
    "# Impute APE (%) using a random forest\n",
    "df = random_forest_impute(\n",
    "    df=df,\n",
    "    target_col='APE (%)',\n",
    "    feature_cols=rf_features_for_hpe_ape\n",
    ")\n",
    "\n",
    "# Combine imputed columns + original features into one list\n",
    "impute_cols = rf_features_for_hpe_ape + [\"HPE (%)\", \"APE (%)\"]\n",
    "impute_cols = list(dict.fromkeys(impute_cols))  # Remove duplicates, maintain order\n",
    "\n",
    "# Create copies for iterative imputation\n",
    "iter_data = df[impute_cols].copy()\n",
    "original_features = df[impute_cols].copy()\n",
    "\n",
    "# Configure IterativeImputer with a RandomForestRegressor\n",
    "iter_imputer = IterativeImputer(\n",
    "    estimator=RandomForestRegressor(\n",
    "        n_estimators=500,\n",
    "        max_depth=20,\n",
    "        min_samples_leaf=5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    max_iter=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit and transform the data with IterativeImputer\n",
    "imputed_array = iter_imputer.fit_transform(iter_data)\n",
    "imputed_iter_df = pd.DataFrame(imputed_array, columns=impute_cols)\n",
    "\n",
    "# Update 'HPE (%)' and 'APE (%)' in the original df\n",
    "df['HPE (%)'] = imputed_iter_df['HPE (%)']\n",
    "df['APE (%)'] = imputed_iter_df['APE (%)']\n",
    "\n",
    "# Revert other features back to original (if the imputer changed them)\n",
    "for col in set(impute_cols) - set([\"HPE (%)\", \"APE (%)\"]):\n",
    "    df[col] = original_features[col]\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.5. Imputing HTV and ATV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Mark rows that are missing 'HTV($m)' and 'ATV($m)'\n",
    "df[\"HTV_missing\"] = df[\"HTV($m)\"].isnull().astype(int)\n",
    "df[\"ATV_missing\"] = df[\"ATV($m)\"].isnull().astype(int)\n",
    "\n",
    "# Features to be used for imputation with XGBoost\n",
    "valuation_features = [\n",
    "    \"Season\", \"Round\",\n",
    "    \"Hpts\", \"Apts\",\n",
    "    \"Home_Form_Points\", \"Away_Form_Points\",\n",
    "    \"Home_Win_Streak\", \"Away_Win_Streak\",\n",
    "    \"Home_H2H_Win_Rate\", \"Away_H2H_Win_Rate\"\n",
    "]\n",
    "\n",
    "def xgb_impute(df, target_col, feature_cols):\n",
    "    \"\"\"\n",
    "    Trains an XGBRegressor to predict 'target_col' using 'feature_cols'.\n",
    "    Fills in missing values in 'target_col' within 'df'.\n",
    "    \"\"\"\n",
    "    # Identify rows with and without missing values for the target\n",
    "    not_missing_mask = df[target_col].notnull()\n",
    "    missing_mask = df[target_col].isnull()\n",
    "\n",
    "    # If there are no missing values, no need to impute\n",
    "    if df[missing_mask].empty:\n",
    "        return df\n",
    "    \n",
    "    # Split the data into two subsets\n",
    "    df_not_missing = df[not_missing_mask].copy()\n",
    "    df_missing = df[missing_mask].copy()\n",
    "\n",
    "    # Configure XGBRegressor\n",
    "    xgb = XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    # Train on rows where the target is not missing\n",
    "    xgb.fit(\n",
    "        df_not_missing[feature_cols],\n",
    "        df_not_missing[target_col]\n",
    "    )\n",
    "\n",
    "    # Predict missing values\n",
    "    imputed_values = xgb.predict(df_missing[feature_cols])\n",
    "\n",
    "    # Fill the main DataFrame with predictions\n",
    "    df.loc[missing_mask, target_col] = imputed_values\n",
    "\n",
    "    return df\n",
    "\n",
    "# Impute missing values for HTV($m) and ATV($m) columns\n",
    "df = xgb_impute(df, target_col=\"HTV($m)\", feature_cols=valuation_features)\n",
    "df = xgb_impute(df, target_col=\"ATV($m)\", feature_cols=valuation_features)\n",
    "\n",
    "# Preview the updated DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rolling_window = 5\n",
    "df_sorted = df.sort_values(by=['HomeTeam', 'Season', 'Round']).reset_index(drop=True)\n",
    "\n",
    "# Rolling average of points for HomeTeam\n",
    "df_sorted['Home_Rolling_Points'] = df_sorted.groupby('HomeTeam')['Hpts'].transform(\n",
    "    lambda x: x.shift(1).rolling(window=rolling_window, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "# Rolling average of points for AwayTeam\n",
    "df_sorted['Away_Rolling_Points'] = df_sorted.groupby('AwayTeam')['Apts'].transform(\n",
    "    lambda x: x.shift(1).rolling(window=rolling_window, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "\n",
    "# Rolling average of possession for HomeTeam\n",
    "df_sorted['Home_Rolling_Possession'] = df_sorted.groupby('HomeTeam')['HTPos_avg'].transform(\n",
    "    lambda x: x.shift(1).rolling(window=rolling_window, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "# Rolling average of possession for AwayTeam\n",
    "df_sorted['Away_Rolling_Possession'] = df_sorted.groupby('AwayTeam')['ATPos_avg'].transform(\n",
    "    lambda x: x.shift(1).rolling(window=rolling_window, min_periods=1).mean()\n",
    ")\n",
    "\n",
    "\n",
    "# List of new rolling feature columns\n",
    "rolling_features = [\n",
    "    'Home_Rolling_Points', 'Away_Rolling_Points',\n",
    "    'Home_Rolling_Possession', 'Away_Rolling_Possession'\n",
    "]\n",
    "\n",
    "# Fill NaN values with the mean of each column\n",
    "for feature in rolling_features:\n",
    "    df_sorted[feature].fillna(df_sorted[feature].mean(), inplace=True)\n",
    "\n",
    "df = df_sorted.copy()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.6. One-Hot Encoding FTR, HomeTeam, and AwayTeam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(\n",
    "    df, \n",
    "    columns=['FTR', 'HomeTeam', 'AwayTeam'],\n",
    "    prefix=['FTR', 'HomeTeam', 'AwayTeam']\n",
    ")\n",
    "\n",
    "# Preview the encoded DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.4.7. Tidying Up the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_copy = df_copy.drop(columns=['FTHG', 'FTAG', 'HTHG', 'HTAG', 'HTR', 'Referee', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR', 'Attendance'])\n",
    "\n",
    "# Display the first few rows\n",
    "df_copy.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Methodology Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_copy.drop(columns=['FTR_A', 'FTR_D', 'FTR_H'])\n",
    "y = df_copy[['FTR_A', 'FTR_D', 'FTR_H']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Training Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Data scaling\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Other Approaches Explored"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Compute class weights\n",
    "# class_weights = compute_class_weight(\n",
    "#     class_weight='balanced',\n",
    "#     classes=np.arange(y.shape[1]),\n",
    "#     y=np.argmax(y, axis=1)\n",
    "# )\n",
    "# class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "def compute_dnn():\n",
    "    # Define the DNN model\n",
    "    model = Sequential([\n",
    "        Dense(512, kernel_regularizer=l2(0.01)),  # Add L2 regularization\n",
    "        BatchNormalization(),  # Batch Normalization\n",
    "        LeakyReLU(alpha=0.1),  # Leaky ReLU activation\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(256, kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(128, kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(y_train.shape[1], activation='softmax')  # Output layer for multi-class classification\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.00005),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    # Set up callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=10,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=100,\n",
    "        batch_size=32,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Visualize training and validation log loss and accuracy\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Plotting Log Loss and Accuracy\n",
    "    plt.figure(figsize=(14, 6))\n",
    "\n",
    "    # Subplot 1: Accuracy\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0, 1)\n",
    "    plt.legend()\n",
    "    plt.title(\"Training and Validation Accuracy\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Subplot 2: Log Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Training Log Loss')\n",
    "    plt.plot(history.history['val_loss'], label='Validation Log Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Log Loss')\n",
    "    plt.ylim(0, 10)  # Adjust if your log loss range differs\n",
    "    plt.legend()\n",
    "    plt.title(\"Training and Validation Log Loss\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    import numpy as np\n",
    "    from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
    "\n",
    "    # Generate predictions on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Convert predicted probabilities and true labels into class indices\n",
    "    y_pred_original = np.argmax(y_pred, axis=1)\n",
    "    y_test_original = np.argmax(y_test, axis=1)\n",
    "\n",
    "    # Display confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_test_original, y_pred_original))\n",
    "\n",
    "    # Display classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test_original, y_pred_original, digits=4))\n",
    "\n",
    "compute_dnn()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Scatter Plot of the Clusters with PCA  \n",
    "def plot_clusters(X, y_pred, kmeans):\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for cluster in np.unique(y_pred):\n",
    "        cluster_points = X_pca[y_pred == cluster]\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], label=f\"Cluster {cluster}\")\n",
    "\n",
    "    # Plot centroids\n",
    "    centroids = pca.transform(kmeans.cluster_centers_)\n",
    "    plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x', s=200, label='Centroids')\n",
    "\n",
    "    plt.title(\"K-Means Clustering Results with PCA\")\n",
    "    \n",
    "    plt.legend([\"H\", \"D\", \"A\"])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate Performance\n",
    "def evaluate_performance(X, y_true, y_pred, kmeans):\n",
    "    print(\"Visualizing Clusters...\")\n",
    "    plot_clusters(X, y_pred, kmeans)\n",
    "    \n",
    "def compute_knn():\n",
    "\n",
    "    y_single = y.idxmax(axis=1).map({'FTR_A': 'Away', 'FTR_D': 'Draw', 'FTR_H': 'Home'})\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y_single)\n",
    "\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y_encoded, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=y_encoded\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, \n",
    "        test_size=0.2, \n",
    "        random_state=42, \n",
    "        stratify=y_train\n",
    "    )\n",
    "\n",
    "\n",
    "    # Initialize K-Means with number of clusters equal to the number of unique classes\n",
    "    n_clusters = len(le.classes_) \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    kmeans.fit(X_train)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    cont_matrix = confusion_matrix(y_train, cluster_labels)\n",
    "    # Apply the Hungarian algorithm to find the optimal mapping\n",
    "    row_ind, col_ind = linear_sum_assignment(-cont_matrix)\n",
    "    cluster_to_label = {}\n",
    "    for cluster, label in zip(col_ind, row_ind):\n",
    "        cluster_to_label[cluster] = label\n",
    "\n",
    "\n",
    "    test_cluster_labels = kmeans.predict(X_test)\n",
    "    # Map cluster labels to actual labels using the optimal cluster_to_label mapping\n",
    "    test_predicted_labels = pd.Series(test_cluster_labels).map(cluster_to_label)\n",
    "    test_predicted_labels = test_predicted_labels.fillna(-1).astype(int)\n",
    "    predicted_labels_original = np.empty_like(test_predicted_labels, dtype=object)\n",
    "\n",
    "    # Identify valid predictions (clusters that were mapped)\n",
    "    valid_indices = test_predicted_labels != -1\n",
    "\n",
    "    # Inverse transform only valid predictions\n",
    "    predicted_labels_original[valid_indices] = le.inverse_transform(test_predicted_labels[valid_indices])\n",
    "\n",
    "    # Assign a placeholder for invalid predictions\n",
    "    predicted_labels_original[~valid_indices] = \"Unknown\"\n",
    "\n",
    "    # Inverse transform true labels for evaluation\n",
    "    y_test_original = le.inverse_transform(y_test)\n",
    "\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(\n",
    "        y_test_original[valid_indices],\n",
    "        predicted_labels_original[valid_indices],\n",
    "        zero_division=0,\n",
    "        digits=4\n",
    "    ))\n",
    "\n",
    "    evaluate_performance(X_train, y_test, y_train, kmeans)\n",
    "\n",
    "\n",
    "compute_knn()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def compute_svm():\n",
    "\n",
    "    y_single = y.idxmax(axis=1).map({'FTR_A': 'Away', 'FTR_D': 'Draw', 'FTR_H': 'Home'})\n",
    "\n",
    "    # Initialize LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "\n",
    "    # Fit and transform the single labels\n",
    "    y_encoded = le.fit_transform(y_single)\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.25, random_state=42, stratify=y_encoded)\n",
    "\n",
    "    # Train SVM model\n",
    "    svm_model = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n",
    "    svm_model.fit(X_train, y_train)\n",
    "\n",
    "    # Predict and evaluate\n",
    "    y_pred = svm_model.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred, target_names=le.classes_, digits=4)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Display performance\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "compute_svm()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Chosen Approach - Gradient Boosted Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold\n",
    "\n",
    "# Convert one-hot encoded labels to single integer labels\n",
    "label_mapping = {'FTR_A': 0, 'FTR_D': 1, 'FTR_H': 2}\n",
    "\n",
    "# Function to convert one-hot to single label\n",
    "def one_hot_to_single(y):\n",
    "    return y.idxmax(axis=1).map(label_mapping)\n",
    "\n",
    "# Apply the function to y_train and y_test\n",
    "y_train_single = one_hot_to_single(y_train)\n",
    "y_test_single = one_hot_to_single(y_test)\n",
    "y_val_single = one_hot_to_single(y_val)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Compute class weights\n",
    "# class_weights = compute_class_weight(\n",
    "#     class_weight='balanced',  # Use 'balanced' strategy\n",
    "#     classes=np.unique(y_train_single),  # Unique class labels\n",
    "#     y=y_train_single  # Training target labels\n",
    "# )\n",
    "\n",
    "# # Map class weights to a dictionary\n",
    "# class_weight_dict = {i: weight for i, weight in enumerate(class_weights)}\n",
    "# print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "# # Assign sample weights based on class weights\n",
    "# sample_weights = np.array([class_weight_dict[label] for label in y_train_single])\n",
    "\n",
    "# Define custom class weights (adjusted manually based on confusion matrix analysis)\n",
    "# class_weight_dict = {0: 1.07, 1: 1.63, 2: 0.91}  # Adjusted weights for Home Win, Draw, Away Win\n",
    "# print(\"Custom Class Weights:\", class_weight_dict)\n",
    "\n",
    "# # Assign sample weights based on custom class weights\n",
    "# sample_weights = np.array([class_weight_dict[label] for label in y_train_single])\n",
    "\n",
    "# # Verify the sample weights\n",
    "# print(\"Sample Weights Example:\", sample_weights[:10])  # Display the first 10 sample weights\n",
    "\n",
    "# Initialise model\n",
    "xgb_clf = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    eval_metric=['mlogloss', 'merror'],\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    \n",
    "    # Lower learning_rate means the model trains more slowly but can generalize better\n",
    "    learning_rate=0.001,     \n",
    "    \n",
    "    # Increased n_estimators to compensate for the lower learning rate\n",
    "    n_estimators=100,      \n",
    "    \n",
    "    # Reduce max_depth to reduce model complexity\n",
    "    max_depth=4,           \n",
    "    \n",
    "    # Increase min_child_weight to require more samples at leaf nodes\n",
    "    min_child_weight=5,    \n",
    "    \n",
    "    # Increase gamma if you want to further penalize splits\n",
    "    gamma=0.5,             \n",
    "    \n",
    "    # Increase regularization to penalize large coefficients\n",
    "    reg_alpha=2.0,\n",
    "    reg_lambda=15.0,\n",
    "    early_stopping=5,\n",
    "    booster='dart',          # Enable dropout-based boosting\n",
    "    sample_type='uniform',   # How to sample weights (can be 'uniform' or 'weighted')\n",
    "    normalize_type='tree',   # How to normalize tree weight (can be 'tree' or 'forest')\n",
    "    rate_drop=0.1,           # Dropout rate for trees (tune as needed)\n",
    "    skip_drop=0.1,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    colsample_bylevel=0.8,   # further reduce the chance of overfitting\n",
    "    colsample_bynode=0.8,\n",
    "    grow_policy='lossguide',    # or 'depthwise'\n",
    "    max_leaves=32,   \n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Map your one-hot labels to single integer labels\n",
    "label_mapping = {'FTR_A': 0, 'FTR_D': 1, 'FTR_H': 2}\n",
    "\n",
    "def one_hot_to_single(y):\n",
    "    return y.idxmax(axis=1).map(label_mapping)\n",
    "\n",
    "y_train_single = one_hot_to_single(y_train)\n",
    "y_val_single = one_hot_to_single(y_val)\n",
    "y_test_single = one_hot_to_single(y_test)\n",
    "\n",
    "\n",
    "# Train the classifier\n",
    "xgb_clf.fit(\n",
    "    X_train, \n",
    "    y_train_single,\n",
    "    eval_set=[(X_train, y_train_single), (X_val, y_val_single)],\n",
    "    verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve evaluation results\n",
    "evals_result = xgb_clf.evals_result()\n",
    "\n",
    "# Extract log loss for training and validation sets\n",
    "train_logloss = evals_result['validation_0']['mlogloss']\n",
    "val_logloss = evals_result['validation_1']['mlogloss']\n",
    "\n",
    "# Extract error rates and convert to accuracy\n",
    "train_merror = evals_result['validation_0']['merror']\n",
    "val_merror = evals_result['validation_1']['merror']\n",
    "\n",
    "train_accuracy = [1 - error for error in train_merror]\n",
    "val_accuracy = [1 - error for error in val_merror]\n",
    "\n",
    "# Determine the number of boosting rounds\n",
    "num_rounds = len(train_logloss)\n",
    "\n",
    "# Plotting Log Loss and Accuracy\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# Subplot 1: Accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, num_rounds + 1), train_accuracy, label='Training Accuracy')\n",
    "plt.plot(range(1, num_rounds + 1), val_accuracy, label='Validation Accuracy')\n",
    "plt.xlabel('Boosting Rounds')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim(0, 1)\n",
    "plt.title('XGBoost Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Subplot 2: Log Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, num_rounds + 1), train_logloss, label='Training Log Loss')\n",
    "plt.plot(range(1, num_rounds + 1), val_logloss, label='Validation Log Loss')\n",
    "plt.xlabel('Boosting Rounds')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.ylim(0, 10)\n",
    "plt.title('XGBoost Training and Validation Log Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_xgb = xgb_clf.predict(X_test)\n",
    "\n",
    "# Calculate test accuracy\n",
    "test_accuracy_xgb = accuracy_score(y_test_single, y_pred_xgb)\n",
    "print(f\"XGBoost Test Accuracy: {test_accuracy_xgb:.2f}\")\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nXGBoost Classification Report:\")\n",
    "print(classification_report(y_test_single, y_pred_xgb, target_names=['FTR_A (Home Win)', 'FTR_D (Draw)', 'FTR_H (Away Win)'], digits=4))\n",
    "\n",
    "# Generate confusion matrix\n",
    "print(\"\\nXGBoost Confusion Matrix:\")\n",
    "conf_matrix = confusion_matrix(y_test_single, y_pred_xgb)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['Home Win', 'Draw', 'Away Win'],\n",
    "            yticklabels=['Home Win', 'Draw', 'Away Win'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('XGBoost Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Final Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for Section 7. Final Predictions on Test Set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
