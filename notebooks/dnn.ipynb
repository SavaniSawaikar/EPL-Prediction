{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_head_to_head(row, matches):\n",
    "    relevant_matches = matches[(\n",
    "        ((matches['HomeTeam'] == row['HomeTeam']) & (matches['AwayTeam'] == row['AwayTeam'])) |\n",
    "        ((matches['HomeTeam'] == row['AwayTeam']) & (matches['AwayTeam'] == row['HomeTeam']))\n",
    "    )]\n",
    "    \n",
    "    home_wins = (\n",
    "        ((relevant_matches['HomeTeam'] == row['HomeTeam']) & (relevant_matches['FTR'] == 'H')) |\n",
    "        ((relevant_matches['AwayTeam'] == row['HomeTeam']) & (relevant_matches['FTR'] == 'A'))\n",
    "    ).sum()\n",
    "    \n",
    "    away_wins = (\n",
    "        ((relevant_matches['HomeTeam'] == row['AwayTeam']) & (relevant_matches['FTR'] == 'H')) |\n",
    "        ((relevant_matches['AwayTeam'] == row['AwayTeam']) & (relevant_matches['FTR'] == 'A'))\n",
    "    ).sum()\n",
    "    \n",
    "    return (home_wins - away_wins) / max(len(relevant_matches), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_directional_head_to_head(row, matches):\n",
    "    relevant_matches = matches[(matches['HomeTeam'] == row['HomeTeam']) & (matches['AwayTeam'] == row['AwayTeam'])]\n",
    "    home_wins = (relevant_matches['FTR'] == 'H').sum()\n",
    "    away_wins = (relevant_matches['FTR'] == 'A').sum()\n",
    "    return (home_wins - away_wins) / max(len(relevant_matches), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_second_h(stat):\n",
    "    if stat.count('H') > 1:\n",
    "        h_index = stat.find('H', stat.find('H') + 1)\n",
    "        return stat[:h_index] + 'A' + stat[h_index + 1:]\n",
    "    return stat.replace('H', 'A')\n",
    "\n",
    "def compute_recent_stats(team, matches, stat, num_games=5):\n",
    "    team_matches = matches[(matches['HomeTeam'] == team) | (matches['AwayTeam'] == team)].tail(num_games)\n",
    "    home_stats = team_matches[team_matches['HomeTeam'] == team][stat].sum()\n",
    "    away_stats = team_matches[team_matches['AwayTeam'] == team][replace_second_h(stat)].sum()\n",
    "    total_stats = home_stats + away_stats\n",
    "    return total_stats / num_games if len(team_matches) > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_points_per_game(team, matches, num_games=5):\n",
    "    team_matches = matches[(matches['HomeTeam'] == team) | (matches['AwayTeam'] == team)].tail(num_games)\n",
    "    points = 0\n",
    "    for _, match in team_matches.iterrows():\n",
    "        if match['HomeTeam'] == team:\n",
    "            if match['FTR'] == 'H':\n",
    "                points += 3\n",
    "            elif match['FTR'] == 'D':\n",
    "                points += 1\n",
    "        elif match['AwayTeam'] == team:\n",
    "            if match['FTR'] == 'A':\n",
    "                points += 3\n",
    "            elif match['FTR'] == 'D':\n",
    "                points += 1\n",
    "    return points / num_games if len(team_matches) > 0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_features(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Head-to-Head Features\n",
    "    df['GeneralHeadToHead'] = df.apply(lambda row: compute_head_to_head(row, df[:row.name]), axis=1)\n",
    "    df['DirectionalHeadToHead'] = df.apply(lambda row: compute_directional_head_to_head(row, df[:row.name]), axis=1)\n",
    "\n",
    "    # Recent Performance Metrics\n",
    "    stats_to_average = ['HS', 'HST', 'HC', 'FTHG', 'HTHG', 'HF', 'HY', 'HR']\n",
    "    for stat in stats_to_average:\n",
    "        df[f'Home_{stat}_Avg'] = df.apply(lambda row: compute_recent_stats(row['HomeTeam'], df[:row.name], stat), axis=1)\n",
    "        df[f'Away_{replace_second_h(stat)}_Avg'] = df.apply(lambda row: compute_recent_stats(row['AwayTeam'], df[:row.name], stat), axis=1)\n",
    "\n",
    "    # Points Per Game Feature\n",
    "    df['Home_PPG'] = df.apply(lambda row: compute_points_per_game(row['HomeTeam'], df[:row.name]), axis=1)\n",
    "    df['Away_PPG'] = df.apply(lambda row: compute_points_per_game(row['AwayTeam'], df[:row.name]), axis=1)\n",
    "\n",
    "    # Fill Default Values\n",
    "    df.fillna({\n",
    "        'GeneralHeadToHead': 0,\n",
    "        'DirectionalHeadToHead': 0,\n",
    "        'Home_HS_Avg': 14,\n",
    "        'Away_AS_Avg': 11,\n",
    "        'Home_HST_Avg': 6,\n",
    "        'Away_AST_Avg': 5,\n",
    "        'Home_HC_Avg': 6,\n",
    "        'Away_AC_Avg': 5,\n",
    "        'Home_FTHG_Avg': 2,\n",
    "        'Away_FTAG_Avg': 1,\n",
    "        'Home_HTHG_Avg': 1,\n",
    "        'Away_HTAG_Avg': 1,\n",
    "        'Home_HF_Avg': 11,\n",
    "        'Away_AF_Avg': 12,\n",
    "        'Home_HY_Avg': 1,\n",
    "        'Away_AY_Avg': 2,\n",
    "        'Home_HR_Avg': 0,\n",
    "        'Away_AR_Avg': 0,\n",
    "        'Home_PPG': 1.5,\n",
    "        'Away_PPG': 1.2\n",
    "    }, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/epl-training.csv')\n",
    "df.drop(index=5700, inplace=True)\n",
    "df = compute_features(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.drop(columns=['Date', 'HomeTeam', 'AwayTeam', 'FTHG', 'FTAG', 'HTHG', 'HTAG', 'HTR', 'Referee', 'HS', 'AS', 'HST', 'AST', 'HC', 'AC', 'HF', 'AF', 'HY', 'AY', 'HR', 'AR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9*len(new_df))\n",
    "X_train = new_df.drop(columns=['FTR']).iloc[:train_size]\n",
    "y_train = new_df['FTR'].iloc[:train_size]\n",
    "X_test = new_df.drop(columns=['FTR']).iloc[train_size:]\n",
    "y_test = new_df['FTR'].iloc[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "model = LogisticRegression(max_iter=1000, class_weight={'H': 1, 'D': 2, 'A': 1})\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "target_mapping = {'H': 0, 'D': 1, 'A': 2}\n",
    "y_train = y_train.map(target_mapping)\n",
    "y_test = y_test.map(target_mapping)\n",
    "\n",
    "y_train_cat = to_categorical(y_train, num_classes=3)\n",
    "y_test_cat = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(128, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.3))  # To prevent overfitting\n",
    "\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "class_weight = {0: 1, 1: 1, 2: 1}\n",
    "history = model.fit(X_train_scaled, y_train_cat, validation_data=(X_test_scaled, y_test_cat), epochs=50, batch_size=32)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_scaled, y_test_cat)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "y_pred_proba = model.predict(X_test_scaled)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "inverse_target_mapping = {0: 'H', 1: 'D', 2: 'A'}\n",
    "y_pred_labels = [inverse_target_mapping[val] for val in y_pred]\n",
    "y_test_labels = [inverse_target_mapping[val] for val in y_test]\n",
    "\n",
    "print(classification_report(y_test_labels, y_pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Test Set\n",
    "df_test = pd.read_csv('../data/epl-test.csv')\n",
    "\n",
    "test_features = []\n",
    "\n",
    "for index, row in df_test.iterrows():\n",
    "    # Use the full training data (df) to compute the necessary stats for the current row\n",
    "    matches = df\n",
    "\n",
    "    # Head-to-Head Features\n",
    "    general_head_to_head = compute_head_to_head(row, matches)\n",
    "    directional_head_to_head = compute_directional_head_to_head(row, matches)\n",
    "\n",
    "    # Recent Performance Metrics\n",
    "    stats_to_average = ['HS', 'HST', 'HC', 'FTHG', 'HTHG', 'HF', 'HY', 'HR']\n",
    "    home_stats = {}\n",
    "    away_stats = {}\n",
    "    for stat in stats_to_average:\n",
    "        home_stats[f'Home_{stat}_Avg'] = compute_recent_stats(row['HomeTeam'], matches, stat)\n",
    "        away_stats[f'Away_{replace_second_h(stat)}_Avg'] = compute_recent_stats(row['AwayTeam'], matches, stat)\n",
    "\n",
    "    # Points Per Game Feature\n",
    "    home_ppg = compute_points_per_game(row['HomeTeam'], matches)\n",
    "    away_ppg = compute_points_per_game(row['AwayTeam'], matches)\n",
    "\n",
    "    # Assuming `home_stats` and `away_stats` are dictionaries\n",
    "    home_stats_keys = list(home_stats.keys())\n",
    "    away_stats_keys = list(away_stats.keys())\n",
    "\n",
    "    # Create interleaved keys\n",
    "    interleaved_keys = [val for pair in zip(home_stats_keys, away_stats_keys) for val in pair]\n",
    "\n",
    "    # Create interleaved dictionary\n",
    "    interleaved_stats = {key: home_stats[key] if key in home_stats else away_stats[key] for key in interleaved_keys}\n",
    "\n",
    "    # Rebuild features_dict with interleaved stats\n",
    "    features_dict = {\n",
    "        'GeneralHeadToHead': general_head_to_head,\n",
    "        'DirectionalHeadToHead': directional_head_to_head,\n",
    "        **interleaved_stats,\n",
    "        'Home_PPG': home_ppg,\n",
    "        'Away_PPG': away_ppg\n",
    "    }\n",
    "\n",
    "    test_features.append(features_dict)\n",
    "\n",
    "# Convert test features into DataFrame\n",
    "df_test_features = pd.DataFrame(test_features)\n",
    "\n",
    "# Fill Default Values\n",
    "df_test_features.fillna({\n",
    "    'GeneralHeadToHead': 0,\n",
    "    'DirectionalHeadToHead': 0,\n",
    "    'Home_HS_Avg': 14,\n",
    "    'Away_AS_Avg': 11,\n",
    "    'Home_HST_Avg': 6,\n",
    "    'Away_AST_Avg': 5,\n",
    "    'Home_HC_Avg': 6,\n",
    "    'Away_AC_Avg': 5,\n",
    "    'Home_FTHG_Avg': 2,\n",
    "    'Away_FTAG_Avg': 1,\n",
    "    'Home_HTHG_Avg': 1,\n",
    "    'Away_HTAG_Avg': 1,\n",
    "    'Home_HF_Avg': 11,\n",
    "    'Away_AF_Avg': 12,\n",
    "    'Home_HY_Avg': 1,\n",
    "    'Away_AY_Avg': 2,\n",
    "    'Home_HR_Avg': 0,\n",
    "    'Away_AR_Avg': 0,\n",
    "    'Home_PPG': 1.5,\n",
    "    'Away_PPG': 1.2\n",
    "}, inplace=True)\n",
    "\n",
    "X_test_new = df_test_features\n",
    "\n",
    "X_test_scaled_new = scaler.transform(X_test_new)\n",
    "\n",
    "y_pred_proba_new = model.predict(X_test_scaled_new)\n",
    "\n",
    "y_pred_new = np.argmax(y_pred_proba_new, axis=1)\n",
    "\n",
    "inverse_target_mapping = {0: 'H', 1: 'D', 2: 'A'}\n",
    "y_pred_labels_new = [inverse_target_mapping[val] for val in y_pred_new]\n",
    "\n",
    "df_test['Predicted_FTR'] = y_pred_labels_new\n",
    "\n",
    "print(df_test[['Date', 'HomeTeam', 'AwayTeam', 'Predicted_FTR']])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
