{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CENG0036 CW - Group I\n",
    "## Section 1 - Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a supplement to the coursework report.\n",
    "\n",
    "The purpose of the codes below is to showcase how to replicate our code in order to arrive at our presented predictions of outcomes of the matches that will take place on the weekend of 1st February 2025.\n",
    "\n",
    "Note that Python 3.9.6 was used in building the codes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 - Importing Libraries\n",
    "Below are all of the libraries used in developing the entirety of the codes that follow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "from datetime import timedelta\n",
    "from collections import deque, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2 - Data Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 - Scrutinising the initial epl-training dataframe\n",
    "The following code was used to identify any duplicates/empty rows in the initital dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of epl before is 9221, which is 101 longer than expected\n",
      "Duplicate rows found at indices [8841, 8842, 8843, 8844, 8845, 8846, 8847, 8848, 8849, 8850, 8851, 8852, 8853, 8854, 8855, 8856, 8857, 8858, 8859, 8860, 8861, 8862, 8863, 8864, 8865, 8866, 8867, 8868, 8869, 8870, 8871, 8872, 8873, 8874, 8875, 8876, 8877, 8878, 8879, 8880, 8881, 8882, 8883, 8884, 8885, 8886, 8887, 8888, 8889, 8890, 8891, 8892, 8893, 8894, 8895, 8896, 8897, 8898, 8899, 8900, 8901, 8902, 8903, 8904, 8905, 8906, 8907, 8908, 8909, 8910, 8911, 8912, 8913, 8914, 8915, 8916, 8917, 8918, 8919, 8920, 8921, 8922, 8923, 8924, 8925, 8926, 8927, 8928, 8929, 8930, 8931, 8932, 8933, 8934, 8935, 8936, 8937, 8938, 8939, 8940]\n",
      "there are 100 duplicates\n",
      "Duplicate rows have been removed and length is now 9120\n"
     ]
    }
   ],
   "source": [
    "epl = pd.read_csv('epl-training.csv')\n",
    "\n",
    "NSeasons = 24\n",
    "MatchesPerSeason = 380\n",
    "ExpectedLength = NSeasons*MatchesPerSeason\n",
    "\n",
    "print(f'Length of epl before is {len(epl)}, which is {len(epl)-ExpectedLength} longer than expected')\n",
    "\n",
    "#removing empty rows\n",
    "epl = epl.dropna(how='all')\n",
    "\n",
    "duplicates = epl.iloc[:, :3].duplicated()\n",
    "if duplicates.any():\n",
    "    dupindex = duplicates[duplicates].index.tolist()\n",
    "    print(f\"Duplicate rows found at indices {dupindex}\")\n",
    "    print(f'there are {len(dupindex)} duplicates')\n",
    "else:\n",
    "    print(\"All rows in the first three columns of epl are unique\")\n",
    "\n",
    "# Eliminate duplicate rows with the indices stored in dupindex\n",
    "epl = epl.drop(dupindex)\n",
    "print(f\"Duplicate rows have been removed and length is now {len(epl)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 - Web Scraping\n",
    "\n",
    "The following is an example code of the webscraping task to retrieve EPL team market values across the years. Note that the same function, with tweaks in some of the parameters, including URL, table class, and row_data keys, was used to webscrape all the other external features, inlcuding match dates across different competitions, posession, attendance, set piece, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```py\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#(year_i=2017) == (year_i =2017-2018 season)\n",
    "def get_market_val(year_i, year_f):\n",
    "    #Fake user agent to avoid 403 forbidden error\n",
    "    headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    for year in range(year_i,year_f):\n",
    "        data_list = []\n",
    "        print(year)\n",
    "        url = f\"https://www.transfermarkt.com/premier-league/startseite/wettbewerb/GB1/plus/?saison_id={year}#google_vignette\"\n",
    "        response = requests.get(url, headers=headers)\n",
    "        print(f'status code is: {response.status_code}')\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        table = soup.find('table', class_ = 'items')\n",
    "        rows = table.find('tbody').find_all('tr')\n",
    "\n",
    "        #Loop through the rows of the table\n",
    "        for row in rows:\n",
    "            columns = row.find_all('td')\n",
    "\n",
    "            row_data = {\n",
    "                'Year': year,\n",
    "                'Club': columns[1].text.strip(),\n",
    "                'TMV': columns[6].text.strip()[1:],  \n",
    "            }\n",
    "\n",
    "            data_list.append(row_data)\n",
    "\n",
    "        df = pd.DataFrame(data_list)\n",
    "\n",
    "        #Remove empty rows\n",
    "        df = df[~df.apply(lambda row:row.astype(str).str.strip().eq('').all(), axis=1)]\n",
    "        combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "        time.sleep(5)\n",
    "\n",
    "\n",
    "    return combined_df.to_csv('Engineered Data/Final Data/marketval.csv', index=False)\n",
    "\n",
    "get_market_val(2000, 2025)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 - Merging Scraped Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.1 - Adding the 14-Day Match Density & Attendance data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ng/c4n7kkzs4csgc8h21qrz97580000gn/T/ipykernel_22741/1866765347.py:19: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  cleanepl['Date'] = pd.to_datetime(cleanepl['Date'])\n",
      "/var/folders/ng/c4n7kkzs4csgc8h21qrz97580000gn/T/ipykernel_22741/1866765347.py:20: UserWarning: Parsing dates in %d/%m/%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  combined['Date'] = pd.to_datetime(combined['Date'])\n",
      "/var/folders/ng/c4n7kkzs4csgc8h21qrz97580000gn/T/ipykernel_22741/1866765347.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_epl['H14'] = combined_epl.apply(lambda row: calculate_matches(row['HomeTeam'], row['Date']), axis=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
      "0  19/08/2000  Charlton       Man City   4.0   0.0   H   2.0   0.0   H   \n",
      "1  19/08/2000   Chelsea       West Ham   4.0   2.0   H   1.0   0.0   H   \n",
      "2  19/08/2000  Coventry  Middlesbrough   1.0   3.0   A   1.0   1.0   D   \n",
      "3  19/08/2000     Derby    Southampton   2.0   2.0   D   1.0   2.0   A   \n",
      "4  19/08/2000     Leeds        Everton   2.0   0.0   H   2.0   0.0   H   \n",
      "\n",
      "            Referee  ...   AC    HF    AF   HY   AY   HR   AR  H14  A14  \\\n",
      "0        Rob Harris  ...  6.0  13.0  12.0  1.0  2.0  0.0  0.0    0    0   \n",
      "1     Graham Barber  ...  7.0  19.0  14.0  1.0  2.0  0.0  0.0    0    0   \n",
      "2      Barry Knight  ...  4.0  15.0  21.0  5.0  3.0  1.0  0.0    0    0   \n",
      "3       Andy D'Urso  ...  8.0  11.0  13.0  1.0  1.0  0.0  0.0    0    0   \n",
      "4  Dermot Gallagher  ...  4.0  21.0  20.0  1.0  3.0  0.0  0.0    0    0   \n",
      "\n",
      "   Attendance  \n",
      "0      20,043  \n",
      "1      34,914  \n",
      "2      20,624  \n",
      "3      27,223  \n",
      "4      40,010  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ng/c4n7kkzs4csgc8h21qrz97580000gn/T/ipykernel_22741/1866765347.py:37: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  combined_epl['A14'] = combined_epl.apply(lambda row: calculate_matches(row['AwayTeam'], row['Date']), axis=1)\n"
     ]
    }
   ],
   "source": [
    "#Importing data scraping files (EPL teams' matches in other comptetitions)\n",
    "EPL_S = pd.read_csv('Scraped Data/COMBINED_EPL.csv') #this is a similar dataframe to epltraining, yet it has the advantage of having attendance data\n",
    "FA_S = pd.read_csv('Scraped Data/COMBINED_FA_E.csv')\n",
    "EFL_S = pd.read_csv('Scraped Data/COMBINED_EFL_E.csv')\n",
    "UCL_S = pd.read_csv('Scraped Data/COMBINED_UCL_E.csv')\n",
    "UEL_S = pd.read_csv('Scraped Data/COMBINED_UEL_E.csv')\n",
    "#clean epl-training (epl) file is the result of the previous code cell.\n",
    "cleanepl = epl\n",
    "\n",
    "#Combining data scraping files into a single dataframe\n",
    "EPL_S.insert(0, 'df name', 'EPL')\n",
    "FA_S.insert(0, 'df name', 'FA')\n",
    "EFL_S.insert(0, 'df name', 'EFL')\n",
    "UCL_S.insert(0, 'df name', 'UCL')\n",
    "UEL_S.insert(0, 'df name', 'UEL')\n",
    "combined = pd.concat([EPL_S, FA_S, EFL_S, UCL_S, UEL_S])\n",
    "\n",
    "#Just to ensure the correct date format\n",
    "cleanepl['Date'] = pd.to_datetime(cleanepl['Date'])\n",
    "combined['Date'] = pd.to_datetime(combined['Date'])\n",
    "\n",
    "combined.sort_values(['Date','HomeTeam'], ascending=[True, True], inplace=True)\n",
    "\n",
    "#Calculating A14/H14 \"14-day match density\" algorithm:\n",
    "def calculate_matches(team, match_date):\n",
    "    StartDate = match_date - timedelta(days=14)\n",
    "    matches = combined[\n",
    "        ((combined[\"HomeTeam\"]==team) | (combined['AwayTeam']==team)) &\n",
    "        (combined['Date'] >= StartDate) &\n",
    "        (combined['Date'] < match_date)\n",
    "        ]\n",
    "    return len(matches)\n",
    "\n",
    "combined_epl = combined[combined['df name'] == 'EPL']\n",
    "\n",
    "combined_epl['H14'] = combined_epl.apply(lambda row: calculate_matches(row['HomeTeam'], row['Date']), axis=1)\n",
    "combined_epl['A14'] = combined_epl.apply(lambda row: calculate_matches(row['AwayTeam'], row['Date']), axis=1)\n",
    "\n",
    "#Merging the combined dataframe with the clean epltraining dataframe to add the A14/H14 + Attendance columns\n",
    "cleanepl = cleanepl.merge(\n",
    "    combined_epl[['Date', 'HomeTeam', 'AwayTeam', 'H14', 'A14', 'Attendance']],\n",
    "    on= ['Date', 'HomeTeam', 'AwayTeam'],\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "#Fixing the Date format\n",
    "cleanepl['Date'] = cleanepl['Date'].dt.strftime('%d/%m/%Y')\n",
    "print(cleanepl.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.2 - Adding the Referee Strictness feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
      "0  19/08/2000  Charlton       Man City   4.0   0.0   H   2.0   0.0   H   \n",
      "1  19/08/2000   Chelsea       West Ham   4.0   2.0   H   1.0   0.0   H   \n",
      "2  19/08/2000  Coventry  Middlesbrough   1.0   3.0   A   1.0   1.0   D   \n",
      "3  19/08/2000     Derby    Southampton   2.0   2.0   D   1.0   2.0   A   \n",
      "4  19/08/2000     Leeds        Everton   2.0   0.0   H   2.0   0.0   H   \n",
      "\n",
      "       Referee  ...    HF    AF   HY   AY   HR   AR  H14  A14  Attendance  \\\n",
      "0     R Harris  ...  13.0  12.0  1.0  2.0  0.0  0.0    0    0      20,043   \n",
      "1     G Barber  ...  19.0  14.0  1.0  2.0  0.0  0.0    0    0      34,914   \n",
      "2     B Knight  ...  15.0  21.0  5.0  3.0  1.0  0.0    0    0      20,624   \n",
      "3     A D'Urso  ...  11.0  13.0  1.0  1.0  0.0  0.0    0    0      27,223   \n",
      "4  D Gallagher  ...  21.0  20.0  1.0  3.0  0.0  0.0    0    0      40,010   \n",
      "\n",
      "   Strictness  \n",
      "0   15.272727  \n",
      "1   13.641026  \n",
      "2   12.253968  \n",
      "3   12.565657  \n",
      "4   10.110236  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# continuing cleanepl from the previous cell under the variable (strepl)\n",
    "strepl = cleanepl\n",
    "\n",
    "#Standardising referee names:\n",
    "def StandardNames(index, name):\n",
    "    if index <= 379:\n",
    "        parts = name.split()\n",
    "        if len(parts) > 1:\n",
    "            return f\"{parts[0][0]} {parts[1]}\" #double check\n",
    "        else:\n",
    "            return name\n",
    "        \n",
    "    elif index <= 549:\n",
    "        parts = name.replace('.','').split()\n",
    "        if len(parts) > 1:\n",
    "            return f\"{parts[0][0]} {parts[-1]}\"\n",
    "        else:\n",
    "            return name\n",
    "    \n",
    "    elif index <= 759:\n",
    "        parts = name.replace(',','').replace('.','').split()\n",
    "        if len(parts) > 1:\n",
    "            return f\"{parts[1][0]} {parts[0]}\"\n",
    "        else:\n",
    "            return name\n",
    "    elif index >= 1855 and index <= 1863:\n",
    "        parts = name.split()\n",
    "        if len(parts) > 1:\n",
    "            return f\"{parts[0][-1]} {parts[1]}\"\n",
    "        else:\n",
    "            return name\n",
    "    else:\n",
    "        return name\n",
    "        \n",
    "strepl['Referee'] = strepl.apply(lambda row: StandardNames(row.name, row['Referee']), axis=1) \n",
    "\n",
    "# Define a lookup dictionary for inconsistent names\n",
    "name_corrections = {\n",
    "    \"D Gallaghe\": \"D Gallagher\",\n",
    "    \"D Gallagh\": \"D Gallagher\"\n",
    "}\n",
    "\n",
    "# Apply corrections to the 'Referee' column\n",
    "strepl['Referee'] = strepl['Referee'].apply(lambda name: name_corrections[name] if name in name_corrections else name)\n",
    "\n",
    "\n",
    "#Initialising dictionaries to 0\n",
    "refs = strepl['Referee'].unique() \n",
    "Y = {ref: 0 for ref in refs} \n",
    "R = {ref: 0 for ref in refs}\n",
    "MatchCount = {ref: 0 for ref in refs}\n",
    "strictness = {}\n",
    "\n",
    "#Loop to count referee stats\n",
    "for index, row in strepl.iterrows(): \n",
    "    ref = row['Referee']\n",
    "    if pd.notna(ref):\n",
    "        Y[ref] += row['AY'] + row['HY']\n",
    "        R[ref] += row['AY'] + row['HY']\n",
    "        MatchCount[ref] += 1\n",
    "\n",
    "#Loop to evaluate referee strictness\n",
    "for ref in refs:\n",
    "    if MatchCount[ref] >0:\n",
    "        strictness[ref] = (Y[ref] + 3*R[ref])/MatchCount[ref]\n",
    "    else:\n",
    "        strictness[ref] = 0\n",
    "\n",
    "#Add to dataframe and add to CSV\n",
    "strepl['Strictness'] = strepl['Referee'].map(strictness)\n",
    "\n",
    "print(strepl.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.3 - Adding the Standings Feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9120/9120 [01:15<00:00, 121.41it/s]\n",
      "100%|██████████| 9120/9120 [01:18<00:00, 116.04it/s]\n",
      "100%|██████████| 9120/9120 [00:00<00:00, 207607.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
      "0  19/08/2000  Charlton       Man City   4.0   0.0   H   2.0   0.0   H   \n",
      "1  19/08/2000   Chelsea       West Ham   4.0   2.0   H   1.0   0.0   H   \n",
      "2  19/08/2000  Coventry  Middlesbrough   1.0   3.0   A   1.0   1.0   D   \n",
      "3  19/08/2000     Derby    Southampton   2.0   2.0   D   1.0   2.0   A   \n",
      "4  19/08/2000     Leeds        Everton   2.0   0.0   H   2.0   0.0   H   \n",
      "\n",
      "       Referee  ...   HR   AR  H14  A14  Attendance  Strictness  Season  \\\n",
      "0     R Harris  ...  0.0  0.0    0    0      20,043   15.272727    2000   \n",
      "1     G Barber  ...  0.0  0.0    0    0      34,914   13.641026    2000   \n",
      "2     B Knight  ...  1.0  0.0    0    0      20,624   12.253968    2000   \n",
      "3     A D'Urso  ...  0.0  0.0    0    0      27,223   12.565657    2000   \n",
      "4  D Gallagher  ...  0.0  0.0    0    0      40,010   10.110236    2000   \n",
      "\n",
      "   Round  Hpts  Apts  \n",
      "0      1     0     0  \n",
      "1      1     0     0  \n",
      "2      1     0     0  \n",
      "3      1     0     0  \n",
      "4      1     0     0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# continuing strepl from the previous cell under the variable (stepl)\n",
    "stepl = strepl\n",
    "\n",
    "#Changing the FTR columns to indicate the name of the winner to simplify the codes below\n",
    "stepl['FTR'] = stepl.apply(lambda row: row['HomeTeam'] if row['FTR']=='H' else ('Draw' if row['FTR'] == 'D' else row['AwayTeam']), axis=1)\n",
    "\n",
    "#Adding season round # values\n",
    "stepl['Season'] = stepl.index // 380\n",
    "stepl['Season'] = stepl['Season'].apply(lambda i: 2000 + i)\n",
    "\n",
    "roundindex = (stepl.index - 10) // 10 + 1\n",
    "stepl['Round'] = (roundindex % 38) + 1 \n",
    "\n",
    "#Calculation algorithm of team points across rounds and seasons\n",
    "def get_pts(team, season, round):\n",
    "    '''\n",
    "    e.g. (season = 2018) == (season = 2018-2019)\n",
    "    '''\n",
    "    if round == 1:\n",
    "        return 0\n",
    "    \n",
    "    prevround = stepl[\n",
    "        (stepl['Season'] == season) & \n",
    "        (stepl['Round'] == round-1)\n",
    "    ]\n",
    "    \n",
    "    #Checking if the team won:\n",
    "    homewin = (prevround['HomeTeam'] == team) & (prevround['FTR'] == team)\n",
    "    awaywin = (prevround['AwayTeam'] == team) & (prevround['FTR'] == team)\n",
    "    draw = ((prevround['HomeTeam'] == team) | (prevround['AwayTeam'] == team)) & (prevround['FTR'] == 'Draw')\n",
    "\n",
    "    if homewin.any() or awaywin.any():\n",
    "        roundpts = 3\n",
    "    elif draw.any():\n",
    "        roundpts = 1\n",
    "    else:\n",
    "        roundpts = 0\n",
    "    \n",
    "    return roundpts + get_pts(team, season, round-1)\n",
    "\n",
    "\n",
    "stepl['Hpts'] = stepl.progress_apply(lambda row: get_pts(row['HomeTeam'], row['Season'], row['Round']), axis=1)\n",
    "stepl['Apts'] = stepl.progress_apply(lambda row: get_pts(row['AwayTeam'], row['Season'], row['Round']), axis=1)\n",
    "\n",
    "#Reversing the FTR column into what it used to be\n",
    "stepl['FTR'] = stepl.progress_apply(lambda row: 'H' if row['FTR']==row['HomeTeam'] else ('D' if row['FTR']=='Draw' else 'A'), axis=1)\n",
    "print(stepl.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.4 Adding the following metrics: team strength, goals scored record, defensive strength, home form points, goal difference form, win streak, and head to head win rate for both the home and away teams. Note that the definition of each metric is discussed in more details in the report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date  HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
      "0  19/08/2000  Charlton       Man City   4.0   0.0   H   2.0   0.0   H   \n",
      "1  19/08/2000   Chelsea       West Ham   4.0   2.0   H   1.0   0.0   H   \n",
      "2  19/08/2000  Coventry  Middlesbrough   1.0   3.0   A   1.0   1.0   D   \n",
      "3  19/08/2000     Derby    Southampton   2.0   2.0   D   1.0   2.0   A   \n",
      "4  19/08/2000     Leeds        Everton   2.0   0.0   H   2.0   0.0   H   \n",
      "\n",
      "       Referee  ...  Home_DS  Away_DS  Home_Form_Points  Away_Form_Points  \\\n",
      "0     R Harris  ...      0.0      0.0               0.0               0.0   \n",
      "1     G Barber  ...      0.0      0.0               0.0               0.0   \n",
      "2     B Knight  ...      0.0      0.0               0.0               0.0   \n",
      "3     A D'Urso  ...      0.0      0.0               0.0               0.0   \n",
      "4  D Gallagher  ...      0.0      0.0               0.0               0.0   \n",
      "\n",
      "   Home_Goal_Diff_Form  Away_Goal_Diff_Form  Home_Win_Streak  Away_Win_Streak  \\\n",
      "0                  0.0                  0.0                0                0   \n",
      "1                  0.0                  0.0                0                0   \n",
      "2                  0.0                  0.0                0                0   \n",
      "3                  0.0                  0.0                0                0   \n",
      "4                  0.0                  0.0                0                0   \n",
      "\n",
      "   Home_H2H_Win_Rate  Away_H2H_Win_Rate  \n",
      "0                0.0                0.0  \n",
      "1                0.0                0.0  \n",
      "2                0.0                0.0  \n",
      "3                0.0                0.0  \n",
      "4                0.0                0.0  \n",
      "\n",
      "[5 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "# continuing stepl from the previous cell under the variable (comepl)\n",
    "comepl = stepl\n",
    "\n",
    "# Temporarily add the HomePoints/AwayPoints features to simplify the codes that follow\n",
    "# Points calculation: Win = 3, Draw = 1, Loss = 0\n",
    "comepl['HomePoints'] = comepl['FTR'].apply(lambda x: 3 if x == 'H' else (1 if x == 'D' else 0))\n",
    "comepl['AwayPoints'] = comepl['FTR'].apply(lambda x: 3 if x == 'A' else (1 if x == 'D' else 0))\n",
    "\n",
    "# Define rolling window size for Form Metrics (e.g., last 10 matches)\n",
    "form_window = 10\n",
    "\n",
    "# Dictionaries to track team stats and rolling metrics\n",
    "team_strength_stats = {}\n",
    "team_goals_scored = {}\n",
    "team_goals_conceded = {}\n",
    "team_form_points = {}\n",
    "team_form_goal_diff = {}\n",
    "team_win_streak = {}\n",
    "\n",
    "# H2H tracking dictionary\n",
    "h2h_record = defaultdict(lambda: {\"matches\": 0, \"home_wins\": 0, \"away_wins\": 0})\n",
    "\n",
    "# Helper functions for Team Strength (overall metrics)\n",
    "def get_team_strength(team):\n",
    "    if team in team_strength_stats and team_strength_stats[team]['games'] > 0:\n",
    "        return team_strength_stats[team]['points'] / team_strength_stats[team]['games']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def update_team_strength(team, points):\n",
    "    if team not in team_strength_stats:\n",
    "        team_strength_stats[team] = {'points': 0, 'games': 0}\n",
    "    team_strength_stats[team]['points'] += points\n",
    "    team_strength_stats[team]['games'] += 1\n",
    "\n",
    "def get_goal_scoring_rate(team):\n",
    "    if team in team_goals_scored and team_strength_stats[team]['games'] > 0:\n",
    "        return team_goals_scored[team] / team_strength_stats[team]['games']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def update_goal_scoring_rate(team, goals):\n",
    "    if team not in team_goals_scored:\n",
    "        team_goals_scored[team] = 0\n",
    "    team_goals_scored[team] += goals\n",
    "\n",
    "def get_defensive_strength(team):\n",
    "    if team in team_goals_conceded and team_strength_stats[team]['games'] > 0:\n",
    "        return team_goals_conceded[team] / team_strength_stats[team]['games']\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def update_defensive_strength(team, goals_conceded):\n",
    "    if team not in team_goals_conceded:\n",
    "        team_goals_conceded[team] = 0\n",
    "    team_goals_conceded[team] += goals_conceded\n",
    "\n",
    "# Helper functions for Team Form (last `form_window` matches)\n",
    "def get_form_points(team):\n",
    "    if team in team_form_points and len(team_form_points[team]) > 0:\n",
    "        return sum(team_form_points[team]) / len(team_form_points[team])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def update_form_points(team, points):\n",
    "    if team not in team_form_points:\n",
    "        team_form_points[team] = deque(maxlen=form_window)\n",
    "    team_form_points[team].append(points)\n",
    "\n",
    "def get_goal_diff_form(team):\n",
    "    if team in team_form_goal_diff and len(team_form_goal_diff[team]) > 0:\n",
    "        return sum(team_form_goal_diff[team])\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def update_goal_diff_form(team, goal_diff):\n",
    "    if team not in team_form_goal_diff:\n",
    "        team_form_goal_diff[team] = deque(maxlen=form_window)\n",
    "    team_form_goal_diff[team].append(goal_diff)\n",
    "\n",
    "def get_win_streak(team):\n",
    "    if team in team_win_streak:\n",
    "        return team_win_streak[team]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def update_win_streak(team, result):\n",
    "    if team not in team_win_streak:\n",
    "        team_win_streak[team] = 0\n",
    "    if result == 3:  # Win\n",
    "        team_win_streak[team] += 1\n",
    "    else:  # Loss or Draw\n",
    "        team_win_streak[team] = 0\n",
    "\n",
    "# H2H functions\n",
    "def calculate_h2h_win_rate(team, opponent, is_home):\n",
    "    record = h2h_record[(team, opponent)]\n",
    "    wins = record['home_wins'] if is_home else record['away_wins']\n",
    "    total_matches = record['matches']\n",
    "    return wins / total_matches if total_matches > 0 else 0\n",
    "\n",
    "def update_h2h_record(home_team, away_team, result):\n",
    "    h2h_record[(home_team, away_team)]['matches'] += 1\n",
    "    h2h_record[(away_team, home_team)]['matches'] += 1\n",
    "    if result == 'H':  # Home win\n",
    "        h2h_record[(home_team, away_team)]['home_wins'] += 1\n",
    "    elif result == 'A':  # Away win\n",
    "        h2h_record[(away_team, home_team)]['away_wins'] += 1\n",
    "\n",
    "# Add columns for Team Strength, Form, and H2H Metrics\n",
    "hts_list = []\n",
    "ats_list = []\n",
    "home_gsr_list = []\n",
    "away_gsr_list = []\n",
    "home_ds_list = []\n",
    "away_ds_list = []\n",
    "home_form_points_list = []\n",
    "away_form_points_list = []\n",
    "home_goal_diff_form_list = []\n",
    "away_goal_diff_form_list = []\n",
    "home_win_streak_list = []\n",
    "away_win_streak_list = []\n",
    "home_h2h_win_rate_list = []\n",
    "away_h2h_win_rate_list = []\n",
    "\n",
    "for _, row in comepl.iterrows():\n",
    "    home_team = row['HomeTeam']\n",
    "    away_team = row['AwayTeam']\n",
    "    result = row['FTR']\n",
    "\n",
    "    # Team Strength Metrics (over entire history)\n",
    "    hts = get_team_strength(home_team)\n",
    "    ats = get_team_strength(away_team)\n",
    "    home_gsr = get_goal_scoring_rate(home_team)\n",
    "    away_gsr = get_goal_scoring_rate(away_team)\n",
    "    home_ds = get_defensive_strength(home_team)\n",
    "    away_ds = get_defensive_strength(away_team)\n",
    "\n",
    "    # Team Form Metrics (last `form_window` matches)\n",
    "    home_form_points = get_form_points(home_team)\n",
    "    away_form_points = get_form_points(away_team)\n",
    "    home_goal_diff_form = get_goal_diff_form(home_team)\n",
    "    away_goal_diff_form = get_goal_diff_form(away_team)\n",
    "    home_win_streak = get_win_streak(home_team)\n",
    "    away_win_streak = get_win_streak(away_team)\n",
    "\n",
    "    # H2H Metrics\n",
    "    home_h2h_win_rate = calculate_h2h_win_rate(home_team, away_team, is_home=True)\n",
    "    away_h2h_win_rate = calculate_h2h_win_rate(away_team, home_team, is_home=False)\n",
    "\n",
    "    # Append calculated values to lists\n",
    "    hts_list.append(hts)\n",
    "    ats_list.append(ats)\n",
    "    home_gsr_list.append(home_gsr)\n",
    "    away_gsr_list.append(away_gsr)\n",
    "    home_ds_list.append(home_ds)\n",
    "    away_ds_list.append(away_ds)\n",
    "    home_form_points_list.append(home_form_points)\n",
    "    away_form_points_list.append(away_form_points)\n",
    "    home_goal_diff_form_list.append(home_goal_diff_form)\n",
    "    away_goal_diff_form_list.append(away_goal_diff_form)\n",
    "    home_win_streak_list.append(home_win_streak)\n",
    "    away_win_streak_list.append(away_win_streak)\n",
    "    home_h2h_win_rate_list.append(home_h2h_win_rate)\n",
    "    away_h2h_win_rate_list.append(away_h2h_win_rate)\n",
    "\n",
    "    # Update Team Strength stats\n",
    "    update_team_strength(home_team, row['HomePoints'])\n",
    "    update_team_strength(away_team, row['AwayPoints'])\n",
    "    update_goal_scoring_rate(home_team, row['FTHG'])  # Goals scored\n",
    "    update_goal_scoring_rate(away_team, row['FTAG'])  # Goals scored\n",
    "    update_defensive_strength(home_team, row['FTAG'])  # Goals conceded\n",
    "    update_defensive_strength(away_team, row['FTHG'])  # Goals conceded\n",
    "\n",
    "    # Update Team Form stats\n",
    "    home_goal_diff = row['FTHG'] - row['FTAG']  # Goal difference\n",
    "    away_goal_diff = row['FTAG'] - row['FTHG']\n",
    "    update_form_points(home_team, row['HomePoints'])\n",
    "    update_form_points(away_team, row['AwayPoints'])\n",
    "    update_goal_diff_form(home_team, home_goal_diff)\n",
    "    update_goal_diff_form(away_team, away_goal_diff)\n",
    "    update_win_streak(home_team, row['HomePoints'])\n",
    "    update_win_streak(away_team, row['AwayPoints'])\n",
    "\n",
    "    # Update H2H stats\n",
    "    update_h2h_record(home_team, away_team, result)\n",
    "\n",
    "# Assign calculated metrics to the dataframe\n",
    "comepl['HTS'] = hts_list\n",
    "comepl['ATS'] = ats_list\n",
    "comepl['HGSR'] = home_gsr_list\n",
    "comepl['AGSR'] = away_gsr_list\n",
    "comepl['Home_DS'] = home_ds_list\n",
    "comepl['Away_DS'] =away_ds_list\n",
    "comepl['Home_Form_Points'] = home_form_points_list\n",
    "comepl['Away_Form_Points'] = away_form_points_list\n",
    "comepl['Home_Goal_Diff_Form'] = home_goal_diff_form_list\n",
    "comepl['Away_Goal_Diff_Form'] = away_goal_diff_form_list\n",
    "comepl['Home_Win_Streak'] = home_win_streak_list\n",
    "comepl['Away_Win_Streak'] = away_win_streak_list\n",
    "comepl['Home_H2H_Win_Rate'] = home_h2h_win_rate_list\n",
    "comepl['Away_H2H_Win_Rate'] = away_h2h_win_rate_list\n",
    "\n",
    "comepl.drop(columns=['HomePoints', 'AwayPoints'], inplace=True)\n",
    "\n",
    "print(comepl.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.3.5: Finally, adding market value, possession stats, and set piece data for both the home and away teams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 46 35 43\n",
      "         Date  HomeTeam       AwayTeam  FTHG  FTAG FTR  HTHG  HTAG HTR  \\\n",
      "0  19/08/2000  Charlton       Man City   4.0   0.0   H   2.0   0.0   H   \n",
      "1  19/08/2000   Chelsea       West Ham   4.0   2.0   H   1.0   0.0   H   \n",
      "2  19/08/2000  Coventry  Middlesbrough   1.0   3.0   A   1.0   1.0   D   \n",
      "3  19/08/2000     Derby    Southampton   2.0   2.0   D   1.0   2.0   A   \n",
      "4  19/08/2000     Leeds        Everton   2.0   0.0   H   2.0   0.0   H   \n",
      "\n",
      "       Referee  ...  Home_H2H_Win_Rate  Away_H2H_Win_Rate  HTV($m)  ATV($m)  \\\n",
      "0     R Harris  ...                0.0                0.0      NaN      NaN   \n",
      "1     G Barber  ...                0.0                0.0      NaN      NaN   \n",
      "2     B Knight  ...                0.0                0.0      NaN      NaN   \n",
      "3     A D'Urso  ...                0.0                0.0      NaN      NaN   \n",
      "4  D Gallagher  ...                0.0                0.0      NaN      NaN   \n",
      "\n",
      "   HTPos_avg  ATPos_avg  HSPE (%)  HPE (%)  ASPE (%)  APE (%)  \n",
      "0        NaN        NaN       NaN      NaN       NaN      NaN  \n",
      "1        NaN        NaN       NaN      NaN       NaN      NaN  \n",
      "2        NaN        NaN       NaN      NaN       NaN      NaN  \n",
      "3        NaN        NaN       NaN      NaN       NaN      NaN  \n",
      "4        NaN        NaN       NaN      NaN       NaN      NaN  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "MarketVal = pd.read_csv('Scraped Data/MarketValues.csv')\n",
    "Posession = pd.read_csv('Scraped Data/PosessionData.csv')\n",
    "SetPiece = pd.read_csv('Scraped Data/SetPiece.csv')\n",
    "\n",
    "# continuing comepl from the previous cell under the variable (finalepl)\n",
    "finalepl = comepl\n",
    "\n",
    "Alterations = {\n",
    "    'Manchester City': 'Man City',\n",
    "    'Arsenal FC': 'Arsenal',\n",
    "    'Chelsea FC': 'Chelsea',\n",
    "    'Liverpool FC': 'Liverpool',\n",
    "    'Manchester United': 'Man United',\n",
    "    'Tottenham Hotspur': 'Tottenham',\n",
    "    'Newcastle United': 'Newcastle',\n",
    "    'Brighton & Hove Albion': 'Brighton',\n",
    "    'West Ham United': 'West Ham',\n",
    "    'Nottingham Forest': \"Nott'm Forest\",\n",
    "    'Brentford FC': 'Brentford',\n",
    "    'Wolverhampton Wanderers': 'Wolves',\n",
    "    'AFC Bournemouth': 'Bournemouth',\n",
    "    'Everton FC': 'Everton',\n",
    "    'Fulham FC': 'Fulham',\n",
    "    'Southampton FC': 'Southampton',\n",
    "    'Leicester City': 'Leicester',\n",
    "    'Ipswich Town': 'Ipswich',\n",
    "    'West Bromwich Albion': 'West Brom',\n",
    "    'Queens Park Rangers': 'QPR',\n",
    "    'Hull City': 'Hull',\n",
    "    'Stoke City': 'Stoke',\n",
    "    'Swansea City': 'Swansea',\n",
    "    'Manchester Utd': 'Man United',\n",
    "    'Newcastle Utd': 'Newcastle',\n",
    "    \"Nott'ham Forest\": \"Nott'm Forest\",\n",
    "    \"Luton Town\": \"Luton\",\n",
    "    'Sheffield Utd': 'Sheffield United',\n",
    "    'Leeds United': 'Leeds',\n",
    "    'Norwich City': 'Norwich',\n",
    "    'Cardiff City': 'Cardiff',\n",
    "    'Birmingham City': 'Birmingham',\n",
    "    'Blackburn Rovers': 'Blackburn',\n",
    "    'Blackpool FC': 'Blackpool',\n",
    "    'Bolton Wanderers': 'Bolton',\n",
    "    'Bradford City': 'Bradford',\n",
    "    'Burnley FC': 'Burnley',\n",
    "    'Charlton Athletic': 'Charlton',\n",
    "    'Coventry City': 'Coventry',\n",
    "    'Derby County': 'Derby',\n",
    "    'Huddersfield Town': 'Huddersfield',\n",
    "    'Middlesbrough FC': 'Middlesbrough',\n",
    "    'Portsmouth FC': 'Portsmouth',\n",
    "    'Reading FC': 'Reading',\n",
    "    'Sunderland AFC': 'Sunderland',\n",
    "    'Watford FC': 'Watford',\n",
    "    'Wigan Athletic': 'Wigan',\n",
    "               }\n",
    "\n",
    "MarketVal['Club'] = MarketVal['Club'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "SetPiece['Team'] = SetPiece['Team'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "Posession['Team'] = Posession['Team'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "\n",
    "# Checking if all names are covered in the dictionary\n",
    "cleaneplteams = list(finalepl['HomeTeam'].unique())\n",
    "MarketValteams = list(MarketVal['Club'].unique())\n",
    "Posessionteams = list(Posession['Team'].unique())\n",
    "setPieceteams = list(SetPiece['Team'].unique())\n",
    "print(len(cleaneplteams),len(MarketValteams),len(Posessionteams), len(setPieceteams))\n",
    "uniqueepl = sorted([team for team in cleaneplteams if team not in MarketValteams])\n",
    "UniqueMarketVal = sorted([team for team in MarketValteams if team not in cleaneplteams])\n",
    "UniquePosession = [team for team in Posessionteams if team not in cleaneplteams]\n",
    "UniqueSetPiece = [team for team in setPieceteams if team not in cleaneplteams]\n",
    "\n",
    "# Applying the dictionary to the dataframes\n",
    "MarketVal['Club'] = MarketVal['Club'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "SetPiece['Team'] = SetPiece['Team'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "Posession['Team'] = Posession['Team'].apply(lambda name: Alterations[name] if name in Alterations else name)\n",
    "\n",
    "\n",
    "# Cleaning the market value data\n",
    "MarketVal['TMV'] = MarketVal['TMV'].apply(\n",
    "    lambda value: float(str(value)[:-2]) * 1000  if isinstance(value, str) and value[-2:] == 'bn' else \n",
    "                  float(str(value)[:-1]) if isinstance(value, str) and value[-1] == 'm' else \n",
    "                  value\n",
    ")\n",
    "\n",
    "#Transferring market values to the epl df\n",
    "finalepl = pd.merge(\n",
    "    finalepl,\n",
    "    MarketVal.rename(columns={'Club':'HomeTeam', 'TMV':'HTV($m)', 'Year':'Season'}),\n",
    "    how='left',\n",
    "    on=['HomeTeam', 'Season'],\n",
    ")\n",
    "\n",
    "finalepl = pd.merge(\n",
    "    finalepl,\n",
    "    MarketVal.rename(columns={'Club':'AwayTeam', 'TMV':'ATV($m)', 'Year':'Season'}),\n",
    "    how='left',\n",
    "    on=['AwayTeam', 'Season'],\n",
    ")\n",
    "\n",
    "# Transferring posession data to the clean epl df\n",
    "Posession['year'] = Posession['year'].apply(lambda name: name[:4])\n",
    "Posession['year'] = Posession['year'].astype(int)\n",
    "Posession['Poss'] = Posession['Poss'].apply(lambda pos: pos/100)\n",
    "Posession = Posession[['Team', 'Poss', 'year']]\n",
    "\n",
    "finalepl = pd.merge(\n",
    "    finalepl,\n",
    "    Posession.rename(columns={'Team':'HomeTeam', 'Poss':'HTPos_avg', 'year':'Season'}),\n",
    "    how='left',\n",
    "    on= ['HomeTeam', 'Season']\n",
    ")\n",
    "\n",
    "finalepl = pd.merge(\n",
    "    finalepl,\n",
    "    Posession.rename(columns={'Team':'AwayTeam', 'Poss':'ATPos_avg', 'year':'Season'}),\n",
    "    how='left',\n",
    "    on= ['AwayTeam', 'Season']\n",
    ")\n",
    "\n",
    "#Transferring set piece values\n",
    "SetPiece = SetPiece.dropna()\n",
    "SetPiece['Season'] = SetPiece['Season'].apply(lambda year: year[:4]).astype(int)\n",
    "SetPiece = SetPiece[['Season','Team','Set Piece Efficiency (%)','Penalty Efficiency (%)']]\n",
    "\n",
    "finalepl = pd.merge(\n",
    "    finalepl,\n",
    "    SetPiece.rename(columns={'Team':'HomeTeam','Set Piece Efficiency (%)': 'HSPE (%)', 'Penalty Efficiency (%)': 'HPE (%)'}),\n",
    "    how='left',\n",
    "    on=['HomeTeam','Season']\n",
    ")\n",
    "\n",
    "finalepl = pd.merge(\n",
    "    finalepl,\n",
    "    SetPiece.rename(columns={'Team':'AwayTeam', 'Set Piece Efficiency (%)': 'ASPE (%)', 'Penalty Efficiency (%)': 'APE (%)'}),\n",
    "    how='left',\n",
    "    on=['AwayTeam','Season']\n",
    ")\n",
    "\n",
    "print(finalepl.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalepl.to_csv('alldata.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
